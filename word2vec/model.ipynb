{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import regex\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val_test(df, props=[.8, .1, .1]):\n",
    "    assert round(sum(props), 2) == 1 and len(props) >= 2\n",
    "    train_df, test_df, val_df = None, None, None\n",
    "\n",
    "    train_size = int(props[0] * len(df))\n",
    "    val_size =  train_size + int(props[1] * len(df))\n",
    "    test_size =val_size + int(props[2] * len(df)) \n",
    "    train_df = df.iloc[0:train_size]\n",
    "    val_df = df.iloc[train_size:val_size]\n",
    "    test_df = df.iloc[val_size:test_size]\n",
    "    \n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "def download_word2vec_embeddings():\n",
    "    print(\"Downloading pre-trained word embeddings from: word2vec-google-news-300.\\n\" \n",
    "          + \"Note: This can take a few minutes.\\n\")\n",
    "    wv = api.load(\"word2vec-google-news-300\")\n",
    "    print(\"\\nLoading complete!\\n\" +\n",
    "          \"Vocabulary size: {}\".format(len(wv.vocab)))\n",
    "    return wv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                                               text author\n",
      "0  id26305  [this, process, however, afforded, me, no, mea...      0\n",
      "1  id17569  [it, never, once, occurred, to, me, that, the,...      1\n",
      "2  id11008  [in, his, left, hand, was, a, gold, snuff, box...      0\n",
      "3  id27763  [how, lovely, is, spring, as, we, looked, from...      2\n",
      "4  id12958  [finding, nothing, else, not, even, gold, the,...      1\n",
      "5  id22965  [a, youth, passed, in, solitude, my, best, yea...      2\n",
      "6  id09674  [the, astronomer, perhaps, at, this, point, to...      0\n",
      "7  id13515  [the, surcingle, hung, in, ribands, from, my, ...      0\n",
      "8  id19322  [i, knew, that, you, could, not, say, to, your...      0\n",
      "9  id00912  [i, confess, that, neither, the, structure, of...      2\n"
     ]
    }
   ],
   "source": [
    "# Opening and preprocessing input file\n",
    "import gensim.models\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from src.preprocess import clean_text\n",
    "\n",
    "data = pd.read_csv('train.csv', quotechar='\"')\n",
    "data.sample(frac=1)\n",
    "\n",
    "\n",
    "# to convert authors into numbers\n",
    "author_to_number = {\n",
    "    'EAP': 0,\n",
    "    'HPL': 1,\n",
    "    'MWS': 2\n",
    "    \n",
    "}\n",
    "\n",
    "# lowercase, removing punctuation and tookenize sentences. Converting labels to int\n",
    "training_text = \"\"\n",
    "for i in range(len(data)):\n",
    "\n",
    "    data['text'][i] = nltk.word_tokenize(regex.sub(r'[^\\w\\s]', '',data['text'][i].lower()))\n",
    "    data['author'][i] = author_to_number[data['author'][i]]\n",
    "\n",
    "print(data[0:10])\n",
    "\n",
    "from src.dataset import *\n",
    "\n",
    "# Splitting dataset and generating vocab\n",
    "train_df, val_df, test_df = split_train_val_test(data)\n",
    "train_vocab, reversed_vocab = generate_vocab_map(train_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD = True\n",
    "# Use fastext or word2vec\n",
    "FASTTEXT = False\n",
    "WINDOW_SIZE = 5\n",
    "\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 128\n",
    "NUM_LAYERS = 1\n",
    "BIDIRECTIONAL = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading pre-trained word embeddings from: word2vec-google-news-300.\n",
      "Note: This can take a few minutes.\n",
      "\n",
      "\n",
      "Loading complete!\n",
      "Vocabulary size: 3000000\n"
     ]
    }
   ],
   "source": [
    "# Downloading or generating word2vec embeddings\n",
    "\n",
    "if DOWNLOAD:\n",
    "    model = download_word2vec_embeddings()\n",
    "else:\n",
    "    if not FASTTEXT:\n",
    "        model = gensim.models.Word2Vec(sentences=train_df['text'], size=EMBEDDING_DIM, window=WINDOW_SIZE)\n",
    "    else:\n",
    "        model = gensim.models.FastText(sentences=train_df['text'], size=EMBEDDING_DIM, window=WINDOW_SIZE)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24500/1539958925.py:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  train_dataset = HeadlineDataset(train_vocab, train_df,model.wv, FASTTEXT)\n",
      "/tmp/ipykernel_24500/1539958925.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  val_dataset = HeadlineDataset(train_vocab, val_df,model.wv, FASTTEXT)\n",
      "/tmp/ipykernel_24500/1539958925.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  test_dataset = HeadlineDataset(train_vocab, test_df,model.wv, FASTTEXT)\n"
     ]
    }
   ],
   "source": [
    "from src.dataset import HeadlineDataset\n",
    "from torch.utils.data import RandomSampler\n",
    "\n",
    "train_dataset = HeadlineDataset(train_vocab, train_df,model.wv, FASTTEXT)\n",
    "val_dataset = HeadlineDataset(train_vocab, val_df,model.wv, FASTTEXT)\n",
    "test_dataset = HeadlineDataset(train_vocab, test_df,model.wv, FASTTEXT)\n",
    "\n",
    "# Now that we're wrapping our dataframes in PyTorch datsets, we can make use of PyTorch Random Samplers.\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "val_sampler = RandomSampler(val_dataset)\n",
    "test_sampler = RandomSampler(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.1797, -0.0913, -0.1553,  ..., -0.1143, -0.0378, -0.1514],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.2256, -0.0195,  0.0908,  ...,  0.0282, -0.1777, -0.0060],\n",
      "         [ 0.0771, -0.1396,  0.1445,  ..., -0.0845,  0.2002, -0.3145],\n",
      "         [-0.0332, -0.0327, -0.0598,  ..., -0.0058,  0.1299, -0.0209],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0884, -0.0317, -0.1226,  ...,  0.0234,  0.2480, -0.1177],\n",
      "         [-0.0581,  0.0581,  0.0133,  ..., -0.1748, -0.0231, -0.0435],\n",
      "         [ 0.0850, -0.0952,  0.1191,  ..., -0.1089,  0.0488, -0.1309],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0510, -0.0008,  0.1826,  ..., -0.1680, -0.2266,  0.0160],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0698, -0.0378, -0.0400,  ...,  0.0041,  0.0009, -0.1196],\n",
      "         [-0.0679,  0.0952,  0.0356,  ...,  0.1270, -0.1035,  0.0476],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0825, -0.1514,  0.0659,  ..., -0.1016, -0.1084, -0.2051],\n",
      "         [ 0.0304, -0.1582,  0.0012,  ...,  0.0371, -0.2041, -0.0898],\n",
      "         [ 0.0260, -0.0019,  0.1855,  ..., -0.1216,  0.2217, -0.0220],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0078, -0.0280,  0.0405,  ...,  0.0396, -0.0605,  0.0081],\n",
      "         [ 0.0947, -0.1187,  0.1182,  ...,  0.0972, -0.0996, -0.0090],\n",
      "         [ 0.2129,  0.0737,  0.0537,  ..., -0.1602, -0.0581, -0.0154],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]) tensor([0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 2, 2, 2, 2, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from src.dataset import collate_fn\n",
    "BATCH_SIZE = 16\n",
    "train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, collate_fn=collate_fn)\n",
    "val_iterator = DataLoader(val_dataset, batch_size=BATCH_SIZE, sampler=val_sampler, collate_fn=collate_fn)\n",
    "test_iterator = DataLoader(test_dataset, batch_size=BATCH_SIZE, sampler=test_sampler, collate_fn=collate_fn)\n",
    "\n",
    "for x, y in test_iterator:\n",
    "    print(x,y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import ClassificationModel\n",
    "\n",
    "model = ClassificationModel(len(train_vocab),embedding_dim=EMBEDDING_DIM,hidden_dim = HIDDEN_DIM,num_layers = NUM_LAYERS,bidirectional = BIDIRECTIONAL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, **instantiate the model with some hyperparameters, and select an appropriate loss function and optimizer.** \n",
    "\n",
    "Hint: we already use sigmoid in our model. What loss functions are availible for binary classification? Feel free to look at PyTorch docs for help!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "criterion, optimizer = torch.nn.CrossEntropyLoss(), torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Training and Evaluation [10 Points]\n",
    "The final part of this HW involves training the model, and evaluating it at each epoch. **Fill out the train and test loops below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the total loss calculated from criterion\n",
    "def train_loop(model, criterion, iterator):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for x, y in tqdm(iterator):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        prediction = model(x)\n",
    "        prediction = torch.squeeze(prediction)\n",
    "        # y = y.round()\n",
    "        # y = y.long()\n",
    "\n",
    " \n",
    "        loss = criterion(prediction,y)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "# returns:\n",
    "# - true: a Python boolean array of all the ground truth values \n",
    "#         taken from the dataset iterator\n",
    "# - pred: a Python boolean array of all model predictions. \n",
    "def val_loop(model, criterion, iterator):\n",
    "    true, pred = [], []\n",
    "    for x, y in tqdm(iterator):\n",
    "    \n",
    "        preds = model(x)\n",
    "        preds = torch.squeeze(preds)\n",
    "        for i_batch in range(len(y)):\n",
    "            true.append(y[i_batch])\n",
    "            pred.append(torch.argmax(preds[i_batch]))\n",
    "            \n",
    "    return true, pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123/123 [00:04<00:00, 27.71it/s]\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24500/2847959152.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbinary_macro_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary_macro_f1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/uni/gatech/fall/lang/project/nlp-project/word2vec/src/eval_utils.py\u001b[0m in \u001b[0;36mbinary_macro_f1\u001b[0;34m(true, pred)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mtn\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# To test your eval implementation, let's see how well the untrained model does on our dev dataset.\n",
    "# It should do pretty poorly.\n",
    "from src.eval_utils import binary_macro_f1, accuracy\n",
    "true, pred = val_loop(model, criterion, val_iterator)\n",
    "# print(binary_macro_f1(true, pred))\n",
    "# print(accuracy(true, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actually training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 979/979 [02:03<00:00,  7.91it/s]\n",
      "100%|██████████| 123/123 [00:04<00:00, 25.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n",
      "TRAIN LOSS: 1067.5374600887299\n",
      "VAL F-1: 0.4037390884816184\n",
      "VAL ACC: 0.40725600408788964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 979/979 [02:07<00:00,  7.66it/s]\n",
      "100%|██████████| 123/123 [00:05<00:00, 20.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1\n",
      "TRAIN LOSS: 1054.2395766973495\n",
      "VAL F-1: 0.43301331334026644\n",
      "VAL ACC: 0.45426673479816043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 979/979 [01:58<00:00,  8.27it/s]\n",
      "100%|██████████| 123/123 [00:04<00:00, 26.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 2\n",
      "TRAIN LOSS: 1051.2215394973755\n",
      "VAL F-1: 0.45096198750224414\n",
      "VAL ACC: 0.4522227899846704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 979/979 [01:58<00:00,  8.24it/s]\n",
      "100%|██████████| 123/123 [00:04<00:00, 25.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 3\n",
      "TRAIN LOSS: 1048.0714154839516\n",
      "VAL F-1: 0.470733061154278\n",
      "VAL ACC: 0.47061829330608074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 979/979 [01:51<00:00,  8.80it/s]\n",
      "100%|██████████| 123/123 [00:04<00:00, 28.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 4\n",
      "TRAIN LOSS: 1045.43911921978\n",
      "VAL F-1: 0.48630174932921094\n",
      "VAL ACC: 0.48696985181400104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 979/979 [02:00<00:00,  8.10it/s]\n",
      "100%|██████████| 123/123 [00:05<00:00, 23.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 5\n",
      "TRAIN LOSS: 1046.2310537695885\n",
      "VAL F-1: 0.4753077765806211\n",
      "VAL ACC: 0.4803270311701584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 256/979 [00:34<02:23,  5.03it/s]"
     ]
    }
   ],
   "source": [
    "TOTAL_EPOCHS = 7\n",
    "for epoch in range(TOTAL_EPOCHS):\n",
    "    train_loss = train_loop(model, criterion, train_iterator)\n",
    "    true, pred = val_loop(model, criterion, val_iterator)\n",
    "    print(f\"EPOCH: {epoch}\")\n",
    "    print(f\"TRAIN LOSS: {train_loss}\")\n",
    "    print(f\"VAL F-1: {binary_macro_f1(true, pred)}\")\n",
    "    print(f\"VAL ACC: {accuracy(true, pred)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the models performance on the held-out test set, using the same val_loop we wrote earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123/123 [00:04<00:00, 25.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST F-1: 0.5651973994448763\n",
      "TEST ACC: 0.5891670924885029\n"
     ]
    }
   ],
   "source": [
    "true, pred = val_loop(model, criterion, test_iterator)\n",
    "print(f\"TEST F-1: {binary_macro_f1(true, pred)}\")\n",
    "print(f\"TEST ACC: {accuracy(true, pred)}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8abf625e542ff33194dd4502f291ce11b7bf8daed732e6d5f31b5a030b27ce17"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
