{"cells":[{"cell_type":"code","execution_count":6,"id":"NqHPu2i_RIdi","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1311,"status":"ok","timestamp":1638983740073,"user":{"displayName":"Andres Langoyo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16006428957903159935"},"user_tz":300},"id":"NqHPu2i_RIdi","outputId":"d981de7f-5e65-4dd7-8c70-e744b28d9d4b"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\n"]}],"source":["!pip install -r requirements.txt"]},{"cell_type":"code","execution_count":null,"id":"851dbe43","metadata":{},"outputs":[],"source":["do_train = False"]},{"cell_type":"code","execution_count":7,"id":"1yv5wo80zFFD","metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1638983740073,"user":{"displayName":"Andres Langoyo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16006428957903159935"},"user_tz":300},"id":"1yv5wo80zFFD"},"outputs":[],"source":["import torch\n","import random\n","import numpy as np\n","import regex\n","\n","RANDOM_SEED = 42\n","torch.manual_seed(RANDOM_SEED)\n","random.seed(RANDOM_SEED)\n","np.random.seed(RANDOM_SEED)\n","\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":8,"id":"_4lpUGTQzFFI","metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1638983740074,"user":{"displayName":"Andres Langoyo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16006428957903159935"},"user_tz":300},"id":"_4lpUGTQzFFI"},"outputs":[],"source":["def split_train_val_test(df, props=[.9, .1]):\n","    train_df, val_df = None, None\n","    \n","    train_size = int(props[0] * len(df))\n","    val_size =  train_size + int(props[1] * len(df))\n","    train_df = df.iloc[0:train_size]\n","    val_df = df.iloc[train_size:]\n","    return train_df, val_df\n"]},{"cell_type":"code","execution_count":9,"id":"u04VW4ugzFFI","metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1638983740074,"user":{"displayName":"Andres Langoyo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16006428957903159935"},"user_tz":300},"id":"u04VW4ugzFFI"},"outputs":[],"source":["import gensim.downloader as api\n","\n","def download_embeddings(fasttetxt):\n","    # https://fasttext.cc/docs/en/english-vectors.html\n","    if fasttetxt:\n","      wv = api.load(\"fasttext-wiki-news-subwords-300\")\n","    else:\n","      \n","      wv = api.load(\"word2vec-google-news-300\")\n","      print(\"\\nLoading complete!\\n\" +\n","            \"Vocabulary size: {}\".format(len(wv.vocab)))\n","    return wv\n"]},{"cell_type":"code","execution_count":10,"id":"23WpDX0rzFFJ","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":241},"executionInfo":{"elapsed":16561,"status":"ok","timestamp":1638983756628,"user":{"displayName":"Andres Langoyo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16006428957903159935"},"user_tz":300},"id":"23WpDX0rzFFJ","outputId":"6ab9b506-108a-472c-9b83-bb467e0717c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>author</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>17613</th>\n","      <td>id08561</td>\n","      <td>[a, lamp, which, had, been, accidentally, left...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17614</th>\n","      <td>id01432</td>\n","      <td>[i, gave, to, each, heroine, of, whom, i, read...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>17615</th>\n","      <td>id22037</td>\n","      <td>[he, got, in, communication, with, dr, houghto...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>17616</th>\n","      <td>id22330</td>\n","      <td>[the, trees, of, the, frequent, forest, belts,...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>17617</th>\n","      <td>id26151</td>\n","      <td>[i, then, moved, forward, and, a, murmuring, s...</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            id                                               text author\n","17613  id08561  [a, lamp, which, had, been, accidentally, left...      0\n","17614  id01432  [i, gave, to, each, heroine, of, whom, i, read...      2\n","17615  id22037  [he, got, in, communication, with, dr, houghto...      1\n","17616  id22330  [the, trees, of, the, frequent, forest, belts,...      1\n","17617  id26151  [i, then, moved, forward, and, a, murmuring, s...      2"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# Opening and preprocessing input file\n","import gensim.models\n","import pandas as pd\n","import nltk\n","nltk.download('punkt')\n","from tqdm import tqdm\n","from preprocess import clean_text\n","\n","data = pd.read_pickle('our_train.pkl')\n","test_df = pd.read_pickle('our_test.pkl')\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# to convert authors into numbers\n","author_to_number = {\n","    'EAP': 0,\n","    'HPL': 1,\n","    'MWS': 2\n","    \n","}\n","\n","# lowercase, removing punctuation and tookenize sentences. Converting labels to int\n","for i in range(len(data)):\n","    data['text'].iloc[i] = nltk.word_tokenize(regex.sub(r'[^\\w\\s]', '',data['text'].iloc[i].lower()))\n","    data['author'].iloc[i] = author_to_number[data['author'].iloc[i]]\n","data.sample(frac=1)\n","for i in range(len(test_df)):\n","    test_df['text'].iloc[i] = nltk.word_tokenize(regex.sub(r'[^\\w\\s]', '',test_df['text'].iloc[i].lower()))\n","    test_df['author'].iloc[i] = author_to_number[test_df['author'].iloc[i]]\n","test_df.sample(frac=1)\n","from dataset import *\n","# Splitting dataset and generating vocab\n","train_df, val_df = split_train_val_test(data)\n","train_vocab, reversed_vocab = generate_vocab_map(train_df)\n","\n","val_df.head()\n","test_df.head()"]},{"cell_type":"code","execution_count":11,"id":"NTDiU36-zFFK","metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1638983756630,"user":{"displayName":"Andres Langoyo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16006428957903159935"},"user_tz":300},"id":"NTDiU36-zFFK"},"outputs":[],"source":["# Use downloaded pretrained embeddings or train our own\n","DOWNLOAD = False\n","# Use fastext or word2vec\n","FASTTEXT = False\n","WINDOW_SIZE = 5\n","\n","EMBEDDING_DIM = 300\n","HIDDEN_DIM = 128\n","NUM_LAYERS = 1\n","BIDIRECTIONAL = True\n"]},{"cell_type":"code","execution_count":12,"id":"kaqaR8CNzFFK","metadata":{"executionInfo":{"elapsed":5637,"status":"ok","timestamp":1638983762255,"user":{"displayName":"Andres Langoyo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16006428957903159935"},"user_tz":300},"id":"kaqaR8CNzFFK"},"outputs":[],"source":["# Downloading or generating word2vec embeddings\n","\n","if DOWNLOAD:\n","    model = download_embeddings(FASTTEXT)\n","else:\n","    if FASTTEXT:\n","        model = gensim.models.FastText(sentences=train_df['text'], size=EMBEDDING_DIM, window=WINDOW_SIZE)\n","    else:\n","        model = gensim.models.Word2Vec(sentences=train_df['text'], size=EMBEDDING_DIM, window=WINDOW_SIZE)\n","                        "]},{"cell_type":"code","execution_count":13,"id":"fVz5UQwTzFFL","metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1638983762255,"user":{"displayName":"Andres Langoyo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16006428957903159935"},"user_tz":300},"id":"fVz5UQwTzFFL"},"outputs":[],"source":["from dataset import HeadlineDataset\n","from torch.utils.data import RandomSampler\n","\n","train_dataset = HeadlineDataset(train_vocab, train_df,model.wv, FASTTEXT)\n","val_dataset = HeadlineDataset(train_vocab, val_df,model.wv, FASTTEXT)\n","test_dataset = HeadlineDataset(train_vocab, test_df,model.wv, FASTTEXT)\n","\n","# Pytorch random samplers\n","train_sampler = RandomSampler(train_dataset)\n","val_sampler = RandomSampler(val_dataset)\n","test_sampler = RandomSampler(test_dataset)"]},{"cell_type":"code","execution_count":14,"id":"gnfaq2kpzFFM","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1638983762255,"user":{"displayName":"Andres Langoyo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16006428957903159935"},"user_tz":300},"id":"gnfaq2kpzFFM","outputId":"c7aa0ab3-5ae4-439f-9e2c-9474ae271ba2"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[-0.0291,  0.0183, -0.0108,  ...,  0.0046,  0.0280, -0.0230],\n","         [-0.1722,  0.1257, -0.1014,  ...,  0.0076,  0.1670, -0.1564],\n","         [-0.3695,  0.1334,  0.0824,  ...,  0.0257,  0.1636, -0.4668],\n","         ...,\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n","\n","        [[-0.2492,  0.2607, -0.2334,  ...,  0.0864,  0.0386,  0.0744],\n","         [-0.1707,  0.2036, -0.1189,  ..., -0.2540,  0.4318, -0.4458],\n","         [-0.1994,  0.1451, -0.0954,  ..., -0.0236,  0.1822, -0.1786],\n","         ...,\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n","\n","        [[-0.1707,  0.2036, -0.1189,  ..., -0.2540,  0.4318, -0.4458],\n","         [-0.1662,  0.1874, -0.1339,  ..., -0.0479,  0.2490, -0.2518],\n","         [-0.0958, -0.1503, -0.0454,  ..., -0.1957,  0.3316,  0.0230],\n","         ...,\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n","\n","        ...,\n","\n","        [[-0.1707,  0.2036, -0.1189,  ..., -0.2540,  0.4318, -0.4458],\n","         [ 0.0203,  0.2086, -0.1722,  ..., -0.0045,  0.1622, -0.0734],\n","         [-0.1768,  0.0650, -0.1075,  ...,  0.1036,  0.1039, -0.0514],\n","         ...,\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n","\n","        [[ 0.0059,  0.3661, -0.3442,  ...,  0.3835,  0.1009, -0.0446],\n","         [-0.0958, -0.1503, -0.0454,  ..., -0.1957,  0.3316,  0.0230],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         ...,\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n","\n","        [[-0.2492,  0.2607, -0.2334,  ...,  0.0864,  0.0386,  0.0744],\n","         [-0.0460,  0.2945, -0.4116,  ...,  0.0978,  0.1793,  0.0029],\n","         [-0.0958, -0.1503, -0.0454,  ..., -0.1957,  0.3316,  0.0230],\n","         ...,\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]) tensor([1, 1, 2, 1, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n"]},{"name":"stderr","output_type":"stream","text":["/content/dataset.py:133: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  tokenized_word_tensor = torch.Tensor(tmp)\n"]}],"source":["from torch.utils.data import DataLoader\n","from dataset import collate_fn\n","BATCH_SIZE = 16\n","# Creating data iterators\n","train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, collate_fn=collate_fn)\n","val_iterator = DataLoader(val_dataset, batch_size=BATCH_SIZE, sampler=val_sampler, collate_fn=collate_fn)\n","test_iterator = DataLoader(test_dataset, batch_size=BATCH_SIZE, sampler=test_sampler, collate_fn=collate_fn)\n","\n","for x, y in test_iterator:\n","    print(x,y)\n","    break"]},{"cell_type":"markdown","id":"FvFz28NgzFFM","metadata":{"id":"FvFz28NgzFFM"},"source":["### Modeling"]},{"cell_type":"code","execution_count":15,"id":"E54k4vH-zFFO","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8751,"status":"ok","timestamp":1638983771002,"user":{"displayName":"Andres Langoyo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16006428957903159935"},"user_tz":300},"id":"E54k4vH-zFFO","outputId":"c349179a-1d7d-4901-8b2d-a08d605172a7"},"outputs":[{"data":{"text/plain":["ClassificationModel(\n","  (LSTM): LSTM(300, 128, batch_first=True, bidirectional=True)\n","  (linear): Linear(in_features=256, out_features=3, bias=True)\n","  (softmax): Softmax(dim=1)\n",")"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["from models import ClassificationModel\n","\n","model = ClassificationModel(len(train_vocab),embedding_dim=EMBEDDING_DIM,hidden_dim = HIDDEN_DIM,num_layers = NUM_LAYERS,bidirectional = BIDIRECTIONAL)\n","\n","model.to(device)"]},{"cell_type":"code","execution_count":16,"id":"4rcqsWzHzFFP","metadata":{"executionInfo":{"elapsed":37,"status":"ok","timestamp":1638983771003,"user":{"displayName":"Andres Langoyo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16006428957903159935"},"user_tz":300},"id":"4rcqsWzHzFFP"},"outputs":[],"source":["from torch.optim import AdamW\n","\n","criterion, optimizer = torch.nn.CrossEntropyLoss(), torch.optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"markdown","id":"xm7rdLC2sCfY","metadata":{"id":"xm7rdLC2sCfY"},"source":["# Testing and Evaluation"]},{"cell_type":"code","execution_count":17,"id":"4WOY7B-azFFP","metadata":{"executionInfo":{"elapsed":33,"status":"ok","timestamp":1638983771003,"user":{"displayName":"Andres Langoyo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16006428957903159935"},"user_tz":300},"id":"4WOY7B-azFFP"},"outputs":[],"source":["# returns the total loss calculated from criterion\n","def train_loop(model, criterion, iterator):\n","    model.train()\n","    total_loss = 0\n","    \n","    for x, y in tqdm(iterator):\n","        x = x.to(device)\n","        y = y.to(device)\n","        optimizer.zero_grad()\n","\n","        prediction = model(x)\n","        prediction = torch.squeeze(prediction)\n","        # y = y.round()\n","        y = y.long()\n","        \n","\n"," \n","        loss = criterion(prediction,y)\n","        total_loss += loss.item()\n","        loss.backward()\n","        optimizer.step()\n","\n","    return total_loss\n","\n","# returns:\n","# - true: a Python boolean array of all the ground truth values \n","#         taken from the dataset iterator\n","# - pred: a Python boolean array of all model predictions. \n","def val_loop(model, criterion, iterator):\n","    true, pred = [], []\n","    for x, y in tqdm(iterator):\n","        x = x.to(device)\n","        y = y.to(device)\n","    \n","        preds = model(x)\n","        preds.to(device)\n","        preds = torch.squeeze(preds)\n","        for i_batch in range(len(y)):\n","            true.append(y[i_batch])\n","            pred.append(torch.argmax(preds[i_batch]))\n","            \n","    return true, pred\n"]},{"cell_type":"code","execution_count":18,"id":"RwyLMPAwzFFQ","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4248,"status":"ok","timestamp":1638983775220,"user":{"displayName":"Andres Langoyo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16006428957903159935"},"user_tz":300},"id":"RwyLMPAwzFFQ","outputId":"d88437ac-41d8-4418-ef0f-9969e435b0c1"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 111/111 [00:03<00:00, 28.62it/s]"]},{"name":"stdout","output_type":"stream","text":["0.22039503530209076\n","0.39160045402951194\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Initial testing\n","from sklearn.metrics import f1_score, accuracy_score\n","\n","from eval_utils import binary_macro_f1, accuracy\n","true, pred = val_loop(model, criterion, val_iterator)\n","true = [x.item() for x in true]\n","pred = [x.item() for x in pred]\n","print(f1_score(true, pred, average='weighted'))\n","print(accuracy_score(true, pred))\n"]},{"cell_type":"markdown","id":"klS-hqCezFFQ","metadata":{"id":"klS-hqCezFFQ"},"source":["### Training the model\n","Do not run this for testing"]},{"cell_type":"code","execution_count":19,"id":"PS8EQy8SzFFQ","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":895512,"status":"ok","timestamp":1638984670699,"user":{"displayName":"Andres Langoyo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16006428957903159935"},"user_tz":300},"id":"PS8EQy8SzFFQ","outputId":"93ab5696-7eb0-4b18-8c88-7f7768d6ff35"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 991/991 [02:02<00:00,  8.11it/s]\n","100%|██████████| 111/111 [00:03<00:00, 28.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["EPOCH: 0\n","TRAIN LOSS: 995.028258740902\n","VAL F-1: 0.5554481090781452\n","VAL ACC: 0.5686719636776391\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 991/991 [02:03<00:00,  8.04it/s]\n","100%|██████████| 111/111 [00:03<00:00, 28.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["EPOCH: 1\n","TRAIN LOSS: 897.2230969071388\n","VAL F-1: 0.57386777105005\n","VAL ACC: 0.5879682179341658\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 991/991 [02:03<00:00,  8.02it/s]\n","100%|██████████| 111/111 [00:03<00:00, 29.07it/s]\n"]},{"name":"stdout","output_type":"stream","text":["EPOCH: 2\n","TRAIN LOSS: 843.6762919425964\n","VAL F-1: 0.6282652441586443\n","VAL ACC: 0.6311010215664018\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 991/991 [02:03<00:00,  8.02it/s]\n","100%|██████████| 111/111 [00:03<00:00, 28.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["EPOCH: 3\n","TRAIN LOSS: 803.1198474466801\n","VAL F-1: 0.6276975370197143\n","VAL ACC: 0.6271282633371169\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 991/991 [02:04<00:00,  7.97it/s]\n","100%|██████████| 111/111 [00:03<00:00, 28.78it/s]\n"]},{"name":"stdout","output_type":"stream","text":["EPOCH: 4\n","TRAIN LOSS: 767.357518941164\n","VAL F-1: 0.6443129423265871\n","VAL ACC: 0.64472190692395\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 991/991 [02:04<00:00,  7.94it/s]\n","100%|██████████| 111/111 [00:03<00:00, 29.09it/s]\n"]},{"name":"stdout","output_type":"stream","text":["EPOCH: 5\n","TRAIN LOSS: 734.2068706154823\n","VAL F-1: 0.6502234465070105\n","VAL ACC: 0.6498297389330306\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 991/991 [02:06<00:00,  7.85it/s]\n","100%|██████████| 111/111 [00:03<00:00, 27.76it/s]\n"]},{"name":"stdout","output_type":"stream","text":["EPOCH: 6\n","TRAIN LOSS: 696.3612449765205\n","VAL F-1: 0.6566678511995899\n","VAL ACC: 0.6583427922814983\n"]}],"source":["if do_train:\n","    TOTAL_EPOCHS = 7\n","    for epoch in range(TOTAL_EPOCHS):\n","        train_loss = train_loop(model, criterion, train_iterator)\n","        true, pred = val_loop(model, criterion, val_iterator)\n","        true = [x.item() for x in true]\n","        pred = [x.item() for x in pred]\n","        print(f\"EPOCH: {epoch}\")\n","        print(f\"TRAIN LOSS: {train_loss}\")\n","        print(f\"VAL F-1: {f1_score(true, pred, average='weighted')}\")\n","        print(f\"VAL ACC: {accuracy_score(true, pred)}\")\n","    file = open('no_downloaded_word2vec.model', 'w+')    \n","    torch.save(model.state_dict(), f'no_downloaded_word2vec.model')\n"]},{"cell_type":"code","execution_count":20,"id":"xZE3RnPw2jo6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1638984670700,"user":{"displayName":"Andres Langoyo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16006428957903159935"},"user_tz":300},"id":"xZE3RnPw2jo6","outputId":"8a1e1891-1fb4-4494-d428-4ac426f75c4a"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# Loading saved model\n","model.load_state_dict(torch.load('no_downloaded_word2vec.model', map_location=torch.device('cpu')))"]},{"cell_type":"code","execution_count":21,"id":"E9S33DF4zFFR","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4950,"status":"ok","timestamp":1638984675644,"user":{"displayName":"Andres Langoyo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16006428957903159935"},"user_tz":300},"id":"E9S33DF4zFFR","outputId":"176d348d-0563-4f36-afb6-53c1fd2e6505"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 123/123 [00:04<00:00, 26.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["TEST F-1: 0.6635476905821555\n","TEST ACC: 0.6653102746693794\n"]}],"source":["# Testing results\n","true, pred = val_loop(model, criterion, test_iterator)\n","true = [x.item() for x in true]\n","pred = [x.item() for x in pred]\n","print(f\"TEST F-1: {f1_score(true, pred, average='weighted')}\")\n","print(f\"TEST ACC: {accuracy_score(true, pred)}\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"no_downloaded⁄word2vec.ipynb","provenance":[]},"interpreter":{"hash":"8abf625e542ff33194dd4502f291ce11b7bf8daed732e6d5f31b5a030b27ce17"},"kernelspec":{"display_name":"Python 3.9.5 64-bit ('base': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"}},"nbformat":4,"nbformat_minor":5}
