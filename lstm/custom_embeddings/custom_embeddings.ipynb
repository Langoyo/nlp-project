{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da730fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/andre/miniconda3/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.10.0)\n",
      "Requirement already satisfied: numpy in /home/andre/miniconda3/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (1.21.2)\n",
      "Requirement already satisfied: tqdm in /home/andre/miniconda3/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (4.61.2)\n",
      "Requirement already satisfied: nltk in /home/andre/miniconda3/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (3.6.2)\n",
      "Requirement already satisfied: pandas in /home/andre/miniconda3/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (1.3.2)\n",
      "Requirement already satisfied: sklearn in /home/andre/miniconda3/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (0.0)\n",
      "Requirement already satisfied: typing-extensions in /home/andre/miniconda3/lib/python3.9/site-packages (from torch->-r requirements.txt (line 1)) (3.10.0.2)\n",
      "Requirement already satisfied: click in /home/andre/miniconda3/lib/python3.9/site-packages (from nltk->-r requirements.txt (line 4)) (8.0.1)\n",
      "Requirement already satisfied: regex in /home/andre/miniconda3/lib/python3.9/site-packages (from nltk->-r requirements.txt (line 4)) (2021.8.28)\n",
      "Requirement already satisfied: joblib in /home/andre/miniconda3/lib/python3.9/site-packages (from nltk->-r requirements.txt (line 4)) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/andre/miniconda3/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/andre/miniconda3/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 5)) (2021.1)\n",
      "Requirement already satisfied: scikit-learn in /home/andre/miniconda3/lib/python3.9/site-packages (from sklearn->-r requirements.txt (line 6)) (0.24.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/andre/miniconda3/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/andre/miniconda3/lib/python3.9/site-packages (from scikit-learn->sklearn->-r requirements.txt (line 6)) (1.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/andre/miniconda3/lib/python3.9/site-packages (from scikit-learn->sklearn->-r requirements.txt (line 6)) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bae7157",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_train = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY #\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "import sklearn\n",
    "# this is how we select a GPU if it's avalible on your computer.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/andre/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17613</th>\n",
       "      <td>id08561</td>\n",
       "      <td>A lamp which had been accidentally left, full ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[a, lamp, which, had, been, accidentally, left...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17614</th>\n",
       "      <td>id01432</td>\n",
       "      <td>I gave to each heroine of whom I read, her bea...</td>\n",
       "      <td>2</td>\n",
       "      <td>[i, gave, to, each, heroine, of, whom, i, read...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17615</th>\n",
       "      <td>id22037</td>\n",
       "      <td>He got in communication with Dr. Houghton of A...</td>\n",
       "      <td>1</td>\n",
       "      <td>[he, got, in, communication, with, dr., hought...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17616</th>\n",
       "      <td>id22330</td>\n",
       "      <td>The trees of the frequent forest belts seem to...</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, trees, of, the, frequent, forest, belts,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17617</th>\n",
       "      <td>id26151</td>\n",
       "      <td>I then moved forward, and a murmuring sound ar...</td>\n",
       "      <td>2</td>\n",
       "      <td>[i, then, moved, forward, ,, and, a, murmuring...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text author  \\\n",
       "17613  id08561  A lamp which had been accidentally left, full ...      0   \n",
       "17614  id01432  I gave to each heroine of whom I read, her bea...      2   \n",
       "17615  id22037  He got in communication with Dr. Houghton of A...      1   \n",
       "17616  id22330  The trees of the frequent forest belts seem to...      1   \n",
       "17617  id26151  I then moved forward, and a murmuring sound ar...      2   \n",
       "\n",
       "                                               tokenized  \n",
       "17613  [a, lamp, which, had, been, accidentally, left...  \n",
       "17614  [i, gave, to, each, heroine, of, whom, i, read...  \n",
       "17615  [he, got, in, communication, with, dr., hought...  \n",
       "17616  [the, trees, of, the, frequent, forest, belts,...  \n",
       "17617  [i, then, moved, forward, ,, and, a, murmuring...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.preprocess import clean_text \n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from tqdm import tqdm\n",
    "from src.preprocess import clean_text\n",
    "\n",
    "data = pd.read_pickle('our_train.pkl')\n",
    "test_df = pd.read_pickle('our_test.pkl')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# to convert authors into numbers\n",
    "author_to_number = {\n",
    "    'EAP': 0,\n",
    "    'HPL': 1,\n",
    "    'MWS': 2\n",
    "    \n",
    "}\n",
    "data[\"tokenized\"] = data[\"text\"].apply(lambda x: nltk.word_tokenize(clean_text(x.lower())))\n",
    "test_df[\"tokenized\"] = test_df[\"text\"].apply(lambda x: nltk.word_tokenize(clean_text(x.lower())))\n",
    "\n",
    "# lowercase, removing punctuation and tookenize sentences. Converting labels to int\n",
    "for i in range(len(data)):\n",
    "    data['author'].iloc[i] = author_to_number[data['author'].iloc[i]]\n",
    "data.sample(frac=1)\n",
    "for i in range(len(test_df)):\n",
    "    test_df['author'].iloc[i] = author_to_number[test_df['author'].iloc[i]]\n",
    "test_df.sample(frac=1)\n",
    "from src.dataset import *\n",
    "# Splitting dataset and generating vocab\n",
    "train_df, val_df = split_train_val_test(data)\n",
    "train_vocab, reversed_vocab = generate_vocab_map(train_df)\n",
    "val_df.head()\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>0</td>\n",
       "      <td>[this, process, ,, however, ,, afforded, me, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>1</td>\n",
       "      <td>[it, never, once, occurred, to, me, that, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>[in, his, left, hand, was, a, gold, snuff, box...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>2</td>\n",
       "      <td>[how, lovely, is, spring, as, we, looked, from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>1</td>\n",
       "      <td>[finding, nothing, else, ,, not, even, gold, ,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author  \\\n",
       "0  id26305  This process, however, afforded me no means of...      0   \n",
       "1  id17569  It never once occurred to me that the fumbling...      1   \n",
       "2  id11008  In his left hand was a gold snuff box, from wh...      0   \n",
       "3  id27763  How lovely is spring As we looked from Windsor...      2   \n",
       "4  id12958  Finding nothing else, not even gold, the Super...      1   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [this, process, ,, however, ,, afforded, me, n...  \n",
       "1  [it, never, once, occurred, to, me, that, the,...  \n",
       "2  [in, his, left, hand, was, a, gold, snuff, box...  \n",
       "3  [how, lovely, is, spring, as, we, looked, from...  \n",
       "4  [finding, nothing, else, ,, not, even, gold, ,...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                     id27080\n",
       "text         It was all mud an' water, an' the sky was dark...\n",
       "author                                                       1\n",
       "tokenized    [it, was, all, mud, an, ', water, ,, an, ', th...\n",
       "Name: 42, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: complete these methods in src/dataset.py\n",
    "from src.dataset import split_train_val_test, generate_vocab_map\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "train_df, val_df = split_train_val_test(df)\n",
    "train_vocab, reverse_vocab = generate_vocab_map(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset import HeadlineDataset\n",
    "from torch.utils.data import RandomSampler\n",
    "#print(train_df)\n",
    "\n",
    "train_dataset = HeadlineDataset(train_vocab, train_df)\n",
    "val_dataset = HeadlineDataset(train_vocab, val_df)\n",
    "test_dataset = HeadlineDataset(train_vocab, test_df)\n",
    "\n",
    "# Now that we're wrapping our dataframes in PyTorch datsets, we can make use of PyTorch Random Samplers.\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "val_sampler = RandomSampler(val_dataset)\n",
    "test_sampler = RandomSampler(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from src.dataset import collate_fn\n",
    "BATCH_SIZE = 16\n",
    "train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, collate_fn=collate_fn)\n",
    "val_iterator = DataLoader(val_dataset, batch_size=BATCH_SIZE, sampler=val_sampler, collate_fn=collate_fn)\n",
    "test_iterator = DataLoader(test_dataset, batch_size=BATCH_SIZE, sampler=test_sampler, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6851,  448,   82,  ...,    0,    0,    0],\n",
      "        [ 101,    2, 1523,  ...,    0,    0,    0],\n",
      "        [   2, 1101,    4,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 161,    2,  247,  ...,    0,    0,    0],\n",
      "        [ 174,    4, 5910,  ...,    0,    0,    0],\n",
      "        [ 101,   36,    4,  ...,    0,    0,    0]]) tensor([1., 1., 2., 1., 0., 0., 2., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for x, y in test_iterator:\n",
    "    print(x,y)\n",
    "    break\n",
    "test_iterator = DataLoader(test_dataset, batch_size=BATCH_SIZE, sampler=test_sampler, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import ClassificationModel\n",
    "model = None\n",
    "model = ClassificationModel(len(train_vocab),embedding_dim=128,hidden_dim = 128,num_layers = 2,bidirectional = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "criterion, optimizer = None, None\n",
    "### YOUR CODE GOES HERE ###\n",
    "criterion, optimizer = torch.nn.CrossEntropyLoss(), torch.optim.Adam(model.parameters(), lr=0.01)# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
    "\n",
    "### YOUR CODE ENDS HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the total loss calculated from criterion\n",
    "def train_loop(model, criterion, iterator):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for x, y in tqdm(iterator):\n",
    "        optimizer.zero_grad()\n",
    "        # x = x.to(device)\n",
    "        # y = y.to(device)\n",
    "        y = y.long()\n",
    "        ### YOUR CODE STARTS HERE (~6 lines of code) ###\n",
    "        prediction = model(x)\n",
    "        prediction = torch.squeeze(prediction)\n",
    "\n",
    " \n",
    "        loss = criterion(prediction,y)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # scheduler.step()\n",
    "        ### YOUR CODE ENDS HERE ###\n",
    "    return total_loss\n",
    "\n",
    "# returns:\n",
    "# - true: a Python boolean array of all the ground truth values \n",
    "#         taken from the dataset iterator\n",
    "# - pred: a Python boolean array of all model predictions. \n",
    "def val_loop(model, criterion, iterator):\n",
    "    true, pred = [], []\n",
    "    ### YOUR CODE STARTS HERE (~8 lines of code) ###\n",
    "    for x, y in tqdm(iterator):\n",
    "        # x = x.to(device)\n",
    "        # y = y.to(device)\n",
    "        # print(\"x\",x)\n",
    "        # print(\"y\",y)  \n",
    "    \n",
    "        preds = model(x)\n",
    "        preds = torch.squeeze(preds)\n",
    "        for i_batch in range(len(y)):\n",
    "            true.append(y[i_batch])\n",
    "            pred.append(torch.argmax(preds[i_batch]))\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "    ### YOUR CODE ENDS HERE ###\n",
    "    return true, pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123/123 [00:06<00:00, 19.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2915791559395867\n",
      "0.3263534218590398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "# To test your eval implementation, let's see how well the untrained model does on our dev dataset.\n",
    "# It should do pretty poorly.\n",
    "from src.eval_utils import binary_macro_f1, accuracy\n",
    "true, pred = val_loop(model, criterion, val_iterator)\n",
    "true = [x.item() for x in true]\n",
    "pred = [x.item() for x in pred]\n",
    "\n",
    "print(f1_score(true, pred, average='weighted'))\n",
    "print(accuracy_score(true, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1102/1102 [04:06<00:00,  4.48it/s]\n",
      "100%|██████████| 123/123 [00:07<00:00, 16.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n",
      "TRAIN LOSS: 880.5618799179792\n",
      "VAL F-1: 0.721644255599444\n",
      "VAL ACC: 0.7236976506639428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1102/1102 [04:13<00:00,  4.35it/s]\n",
      "100%|██████████| 123/123 [00:07<00:00, 16.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1\n",
      "TRAIN LOSS: 562.099752612412\n",
      "VAL F-1: 0.7553912422501342\n",
      "VAL ACC: 0.7553626149131767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1102/1102 [03:56<00:00,  4.67it/s]\n",
      "100%|██████████| 123/123 [00:06<00:00, 18.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 2\n",
      "TRAIN LOSS: 446.0243306942284\n",
      "VAL F-1: 0.7628705108686338\n",
      "VAL ACC: 0.763023493360572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1102/1102 [04:19<00:00,  4.25it/s]\n",
      "100%|██████████| 123/123 [00:07<00:00, 17.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 3\n",
      "TRAIN LOSS: 407.40921580418944\n",
      "VAL F-1: 0.7609739244585791\n",
      "VAL ACC: 0.7620020429009193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1102/1102 [04:24<00:00,  4.17it/s]\n",
      "100%|██████████| 123/123 [00:06<00:00, 18.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 4\n",
      "TRAIN LOSS: 410.00900747440755\n",
      "VAL F-1: 0.7420459583746026\n",
      "VAL ACC: 0.7415730337078652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1102/1102 [04:34<00:00,  4.02it/s]\n",
      "100%|██████████| 123/123 [00:06<00:00, 18.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 5\n",
      "TRAIN LOSS: 378.71402362920344\n",
      "VAL F-1: 0.7384054405505677\n",
      "VAL ACC: 0.7390194075587334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1102/1102 [04:52<00:00,  3.77it/s]\n",
      "100%|██████████| 123/123 [00:07<00:00, 17.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 6\n",
      "TRAIN LOSS: 412.0156566388905\n",
      "VAL F-1: 0.7348490368971985\n",
      "VAL ACC: 0.7354443309499489\n"
     ]
    }
   ],
   "source": [
    "if do_train:\n",
    "    TOTAL_EPOCHS = 7\n",
    "    for epoch in range(TOTAL_EPOCHS):\n",
    "        train_loss = train_loop(model, criterion, train_iterator)\n",
    "        true, pred = val_loop(model, criterion, val_iterator)\n",
    "        print(f\"EPOCH: {epoch}\")\n",
    "        print(f\"TRAIN LOSS: {train_loss}\")\n",
    "        print(f\"VAL F-1: {f1_score(true, pred, average='weighted')}\")\n",
    "        print(f\"VAL ACC: {accuracy_score(true, pred)}\")\n",
    "    file = open('custom_embeddings.model', 'w+')    \n",
    "    torch.save(model.state_dict(), f'custom_embeddings.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40ff7e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('custom_embeddings.model', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123/123 [00:06<00:00, 18.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST F-1: 0.8768857919934083\n",
      "TEST ACC: 0.8769074262461851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "true, pred = val_loop(model, criterion, test_iterator)\n",
    "print(f\"TEST F-1: {f1_score(true, pred, average='weighted')}\")\n",
    "print(f\"TEST ACC: {accuracy_score(true, pred)}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd4653ffb3619e38e0f162702933cb5a2e71428b78fc95dca1bdeccba0429964"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
