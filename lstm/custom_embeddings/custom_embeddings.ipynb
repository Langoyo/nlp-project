{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da730fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/andre/miniconda3/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.10.0)\n",
      "Requirement already satisfied: numpy in /home/andre/miniconda3/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (1.21.2)\n",
      "Requirement already satisfied: tqdm in /home/andre/miniconda3/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (4.61.2)\n",
      "Requirement already satisfied: nltk in /home/andre/miniconda3/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (3.6.2)\n",
      "Requirement already satisfied: pandas in /home/andre/miniconda3/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (1.3.2)\n",
      "Requirement already satisfied: sklearn in /home/andre/miniconda3/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (0.0)\n",
      "Requirement already satisfied: typing-extensions in /home/andre/miniconda3/lib/python3.9/site-packages (from torch->-r requirements.txt (line 1)) (3.10.0.2)\n",
      "Requirement already satisfied: click in /home/andre/miniconda3/lib/python3.9/site-packages (from nltk->-r requirements.txt (line 4)) (8.0.1)\n",
      "Requirement already satisfied: joblib in /home/andre/miniconda3/lib/python3.9/site-packages (from nltk->-r requirements.txt (line 4)) (1.0.1)\n",
      "Requirement already satisfied: regex in /home/andre/miniconda3/lib/python3.9/site-packages (from nltk->-r requirements.txt (line 4)) (2021.8.28)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/andre/miniconda3/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 5)) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/andre/miniconda3/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: scikit-learn in /home/andre/miniconda3/lib/python3.9/site-packages (from sklearn->-r requirements.txt (line 6)) (0.24.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/andre/miniconda3/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/andre/miniconda3/lib/python3.9/site-packages (from scikit-learn->sklearn->-r requirements.txt (line 6)) (1.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/andre/miniconda3/lib/python3.9/site-packages (from scikit-learn->sklearn->-r requirements.txt (line 6)) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bae7157",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_train = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andre/miniconda3/lib/python3.9/site-packages/torch/cuda/__init__.py:80: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# DO NOT MODIFY #\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "import sklearn\n",
    "# this is how we select a GPU if it's avalible on your computer.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/andre/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17613</th>\n",
       "      <td>id08561</td>\n",
       "      <td>A lamp which had been accidentally left, full ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[a, lamp, which, had, been, accidentally, left...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17614</th>\n",
       "      <td>id01432</td>\n",
       "      <td>I gave to each heroine of whom I read, her bea...</td>\n",
       "      <td>2</td>\n",
       "      <td>[i, gave, to, each, heroine, of, whom, i, read...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17615</th>\n",
       "      <td>id22037</td>\n",
       "      <td>He got in communication with Dr. Houghton of A...</td>\n",
       "      <td>1</td>\n",
       "      <td>[he, got, in, communication, with, dr., hought...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17616</th>\n",
       "      <td>id22330</td>\n",
       "      <td>The trees of the frequent forest belts seem to...</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, trees, of, the, frequent, forest, belts,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17617</th>\n",
       "      <td>id26151</td>\n",
       "      <td>I then moved forward, and a murmuring sound ar...</td>\n",
       "      <td>2</td>\n",
       "      <td>[i, then, moved, forward, ,, and, a, murmuring...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text author  \\\n",
       "17613  id08561  A lamp which had been accidentally left, full ...      0   \n",
       "17614  id01432  I gave to each heroine of whom I read, her bea...      2   \n",
       "17615  id22037  He got in communication with Dr. Houghton of A...      1   \n",
       "17616  id22330  The trees of the frequent forest belts seem to...      1   \n",
       "17617  id26151  I then moved forward, and a murmuring sound ar...      2   \n",
       "\n",
       "                                               tokenized  \n",
       "17613  [a, lamp, which, had, been, accidentally, left...  \n",
       "17614  [i, gave, to, each, heroine, of, whom, i, read...  \n",
       "17615  [he, got, in, communication, with, dr., hought...  \n",
       "17616  [the, trees, of, the, frequent, forest, belts,...  \n",
       "17617  [i, then, moved, forward, ,, and, a, murmuring...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.preprocess import clean_text \n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from tqdm import tqdm\n",
    "from src.preprocess import clean_text\n",
    "\n",
    "data = pd.read_pickle('our_train.pkl')\n",
    "test_df = pd.read_pickle('our_test.pkl')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# to convert authors into numbers\n",
    "author_to_number = {\n",
    "    'EAP': 0,\n",
    "    'HPL': 1,\n",
    "    'MWS': 2\n",
    "    \n",
    "}\n",
    "data[\"tokenized\"] = data[\"text\"].apply(lambda x: nltk.word_tokenize(clean_text(x.lower())))\n",
    "test_df[\"tokenized\"] = test_df[\"text\"].apply(lambda x: nltk.word_tokenize(clean_text(x.lower())))\n",
    "\n",
    "# lowercase, removing punctuation and tookenize sentences. Converting labels to int\n",
    "for i in range(len(data)):\n",
    "    data['author'].iloc[i] = author_to_number[data['author'].iloc[i]]\n",
    "data.sample(frac=1)\n",
    "for i in range(len(test_df)):\n",
    "    test_df['author'].iloc[i] = author_to_number[test_df['author'].iloc[i]]\n",
    "test_df.sample(frac=1)\n",
    "from src.dataset import *\n",
    "# Splitting dataset and generating vocab\n",
    "train_df, val_df = split_train_val_test(data)\n",
    "train_vocab, reversed_vocab = generate_vocab_map(train_df)\n",
    "val_df.head()\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: complete these methods in src/dataset.py\n",
    "from src.dataset import split_train_val_test, generate_vocab_map\n",
    "\n",
    "train_df, val_df = split_train_val_test(data)\n",
    "train_vocab, reverse_vocab = generate_vocab_map(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset import HeadlineDataset\n",
    "from torch.utils.data import RandomSampler\n",
    "#print(train_df)\n",
    "\n",
    "train_dataset = HeadlineDataset(train_vocab, train_df)\n",
    "val_dataset = HeadlineDataset(train_vocab, val_df)\n",
    "test_dataset = HeadlineDataset(train_vocab, test_df)\n",
    "\n",
    "# Now that we're wrapping our dataframes in PyTorch datsets, we can make use of PyTorch Random Samplers.\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "val_sampler = RandomSampler(val_dataset)\n",
    "test_sampler = RandomSampler(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from src.dataset import collate_fn\n",
    "BATCH_SIZE = 16\n",
    "train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, collate_fn=collate_fn)\n",
    "val_iterator = DataLoader(val_dataset, batch_size=BATCH_SIZE, sampler=val_sampler, collate_fn=collate_fn)\n",
    "test_iterator = DataLoader(test_dataset, batch_size=BATCH_SIZE, sampler=test_sampler, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2099,  969,   50,  ...,    0,    0,    0],\n",
      "        [  17,   12,  486,  ...,    0,    0,    0],\n",
      "        [  12,  441,   54,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 601,   12,  594,  ...,    0,    0,    0],\n",
      "        [  60,   54, 2239,  ...,    0,    0,    0],\n",
      "        [  17,   40,   54,  ...,    0,    0,    0]]) tensor([1., 1., 2., 1., 0., 0., 2., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for x, y in test_iterator:\n",
    "    print(x,y)\n",
    "    break\n",
    "test_iterator = DataLoader(test_dataset, batch_size=BATCH_SIZE, sampler=test_sampler, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import ClassificationModel\n",
    "model = None\n",
    "model = ClassificationModel(len(train_vocab),embedding_dim=128,hidden_dim = 128,num_layers = 2,bidirectional = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "criterion, optimizer = None, None\n",
    "### YOUR CODE GOES HERE ###\n",
    "criterion, optimizer = torch.nn.CrossEntropyLoss(), torch.optim.Adam(model.parameters(), lr=0.01)# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
    "\n",
    "### YOUR CODE ENDS HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the total loss calculated from criterion\n",
    "def train_loop(model, criterion, iterator):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for x, y in tqdm(iterator):\n",
    "        optimizer.zero_grad()\n",
    "        # x = x.to(device)\n",
    "        # y = y.to(device)\n",
    "        y = y.long()\n",
    "        ### YOUR CODE STARTS HERE (~6 lines of code) ###\n",
    "        prediction = model(x)\n",
    "        prediction = torch.squeeze(prediction)\n",
    "\n",
    " \n",
    "        loss = criterion(prediction,y)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # scheduler.step()\n",
    "        ### YOUR CODE ENDS HERE ###\n",
    "    return total_loss\n",
    "\n",
    "# returns:\n",
    "# - true: a Python boolean array of all the ground truth values \n",
    "#         taken from the dataset iterator\n",
    "# - pred: a Python boolean array of all model predictions. \n",
    "def val_loop(model, criterion, iterator):\n",
    "    true, pred = [], []\n",
    "    ### YOUR CODE STARTS HERE (~8 lines of code) ###\n",
    "    for x, y in tqdm(iterator):\n",
    "        # x = x.to(device)\n",
    "        # y = y.to(device)\n",
    "        # print(\"x\",x)\n",
    "        # print(\"y\",y)  \n",
    "    \n",
    "        preds = model(x)\n",
    "        preds = torch.squeeze(preds)\n",
    "        for i_batch in range(len(y)):\n",
    "            true.append(y[i_batch])\n",
    "            pred.append(torch.argmax(preds[i_batch]))\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "    ### YOUR CODE ENDS HERE ###\n",
    "    return true, pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:06<00:00, 17.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2772258195358197\n",
      "0.33087400681044266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "# To test your eval implementation, let's see how well the untrained model does on our dev dataset.\n",
    "# It should do pretty poorly.\n",
    "from src.eval_utils import binary_macro_f1, accuracy\n",
    "true, pred = val_loop(model, criterion, val_iterator)\n",
    "true = [x.item() for x in true]\n",
    "pred = [x.item() for x in pred]\n",
    "\n",
    "print(f1_score(true, pred, average='weighted'))\n",
    "print(accuracy_score(true, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 991/991 [03:34<00:00,  4.63it/s]\n",
      "100%|██████████| 111/111 [00:05<00:00, 19.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n",
      "TRAIN LOSS: 842.3033836483955\n",
      "VAL F-1: 0.7434612435126736\n",
      "VAL ACC: 0.7434733257661748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 991/991 [03:25<00:00,  4.82it/s]\n",
      "100%|██████████| 111/111 [00:05<00:00, 18.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1\n",
      "TRAIN LOSS: 507.46212339401245\n",
      "VAL F-1: 0.7758094068951569\n",
      "VAL ACC: 0.7758229284903518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 991/991 [03:28<00:00,  4.76it/s]\n",
      "100%|██████████| 111/111 [00:05<00:00, 21.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 2\n",
      "TRAIN LOSS: 379.50270769000053\n",
      "VAL F-1: 0.7751865717689083\n",
      "VAL ACC: 0.775255391600454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 991/991 [03:41<00:00,  4.48it/s]\n",
      "100%|██████████| 111/111 [00:05<00:00, 19.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 3\n",
      "TRAIN LOSS: 372.5675397180021\n",
      "VAL F-1: 0.7714581617255469\n",
      "VAL ACC: 0.7712826333711691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 991/991 [03:48<00:00,  4.35it/s]\n",
      "100%|██████████| 111/111 [00:05<00:00, 19.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 4\n",
      "TRAIN LOSS: 320.59249669127166\n",
      "VAL F-1: 0.7638888327691284\n",
      "VAL ACC: 0.7639046538024972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 991/991 [03:55<00:00,  4.21it/s]\n",
      "100%|██████████| 111/111 [00:05<00:00, 19.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 5\n",
      "TRAIN LOSS: 294.2133383564651\n",
      "VAL F-1: 0.7645087620512302\n",
      "VAL ACC: 0.764472190692395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 991/991 [04:16<00:00,  3.86it/s]\n",
      "100%|██████████| 111/111 [00:05<00:00, 20.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 6\n",
      "TRAIN LOSS: 264.06260167155415\n",
      "VAL F-1: 0.769842267289176\n",
      "VAL ACC: 0.7701475595913735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if do_train:\n",
    "    TOTAL_EPOCHS = 7\n",
    "    for epoch in range(TOTAL_EPOCHS):\n",
    "        train_loss = train_loop(model, criterion, train_iterator)\n",
    "        true, pred = val_loop(model, criterion, val_iterator)\n",
    "        print(f\"EPOCH: {epoch}\")\n",
    "        print(f\"TRAIN LOSS: {train_loss}\")\n",
    "        print(f\"VAL F-1: {f1_score(true, pred, average='weighted')}\")\n",
    "        print(f\"VAL ACC: {accuracy_score(true, pred)}\")\n",
    "    file = open('custom_embeddings.model', 'w+')    \n",
    "    torch.save(model.state_dict(), f'custom_embeddings.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40ff7e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('custom_embeddings.model', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123/123 [00:06<00:00, 18.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST F-1: 0.7509899052091041\n",
      "TEST ACC: 0.7507629704984741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "true, pred = val_loop(model, criterion, test_iterator)\n",
    "print(f\"TEST F-1: {f1_score(true, pred, average='weighted')}\")\n",
    "print(f\"TEST ACC: {accuracy_score(true, pred)}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd4653ffb3619e38e0f162702933cb5a2e71428b78fc95dca1bdeccba0429964"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
