{"nbformat":4,"nbformat_minor":5,"metadata":{"accelerator":"GPU","colab":{"name":"download/word2vec.ipynb","provenance":[],"collapsed_sections":[]},"interpreter":{"hash":"8abf625e542ff33194dd4502f291ce11b7bf8daed732e6d5f31b5a030b27ce17"},"kernelspec":{"display_name":"Python 3.9.5 64-bit ('base': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"}},"cells":[{"cell_type":"code","metadata":{"id":"1yv5wo80zFFD","executionInfo":{"status":"ok","timestamp":1638632684707,"user_tz":300,"elapsed":6012,"user":{"displayName":"Andrés Langoyo Martín","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12914381003507187562"}}},"source":["import torch\n","import random\n","import numpy as np\n","import regex\n","\n","RANDOM_SEED = 42\n","torch.manual_seed(RANDOM_SEED)\n","random.seed(RANDOM_SEED)\n","np.random.seed(RANDOM_SEED)\n","\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"id":"1yv5wo80zFFD","execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"_4lpUGTQzFFI","executionInfo":{"status":"ok","timestamp":1638632684708,"user_tz":300,"elapsed":7,"user":{"displayName":"Andrés Langoyo Martín","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12914381003507187562"}}},"source":["def split_train_val_test(df, props=[.8, .1, .1]):\n","    assert round(sum(props), 2) == 1 and len(props) >= 2\n","    train_df, test_df, val_df = None, None, None\n","\n","    train_size = int(props[0] * len(df))\n","    val_size =  train_size + int(props[1] * len(df))\n","    test_size =val_size + int(props[2] * len(df)) \n","    train_df = df.iloc[0:train_size]\n","    val_df = df.iloc[train_size:val_size]\n","    test_df = df.iloc[val_size:test_size]\n","    \n","    return train_df, val_df, test_df"],"id":"_4lpUGTQzFFI","execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"u04VW4ugzFFI","executionInfo":{"status":"ok","timestamp":1638632685583,"user_tz":300,"elapsed":881,"user":{"displayName":"Andrés Langoyo Martín","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12914381003507187562"}}},"source":["import gensim.downloader as api\n","\n","def download_embeddings(fasttetxt):\n","    # https://fasttext.cc/docs/en/english-vectors.html\n","    if fasttetxt:\n","      wv = api.load(\"fasttext-wiki-news-subwords-300\")\n","    else:\n","      \n","      wv = api.load(\"word2vec-google-news-300\")\n","      print(\"\\nLoading complete!\\n\" +\n","            \"Vocabulary size: {}\".format(len(wv.vocab)))\n","    return wv\n"],"id":"u04VW4ugzFFI","execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"23WpDX0rzFFJ","executionInfo":{"status":"ok","timestamp":1638632699969,"user_tz":300,"elapsed":14388,"user":{"displayName":"Andrés Langoyo Martín","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12914381003507187562"}},"outputId":"74dbbc16-771c-4dd4-a086-9a74c6e3ad61"},"source":["# Opening and preprocessing input file\n","import gensim.models\n","import pandas as pd\n","import nltk\n","nltk.download('punkt')\n","from tqdm import tqdm\n","from src.preprocess import clean_text\n","\n","data = pd.read_csv('train.csv', quotechar='\"')\n","data.sample(frac=1)\n","\n","\n","# to convert authors into numbers\n","author_to_number = {\n","    'EAP': 0,\n","    'HPL': 1,\n","    'MWS': 2\n","    \n","}\n","\n","# lowercase, removing punctuation and tookenize sentences. Converting labels to int\n","training_text = \"\"\n","for i in range(len(data)):\n","\n","    data['text'][i] = nltk.word_tokenize(regex.sub(r'[^\\w\\s]', '',data['text'][i].lower()))\n","    data['author'][i] = author_to_number[data['author'][i]]\n","\n","print(data[0:10])\n","print(len(data))\n","\n","from src.dataset import *\n","\n","# Splitting dataset and generating vocab\n","train_df, val_df, test_df = split_train_val_test(data)\n","train_vocab, reversed_vocab = generate_vocab_map(train_df)\n","\n"],"id":"23WpDX0rzFFJ","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","        id                                               text author\n","0  id26305  [this, process, however, afforded, me, no, mea...      0\n","1  id17569  [it, never, once, occurred, to, me, that, the,...      1\n","2  id11008  [in, his, left, hand, was, a, gold, snuff, box...      0\n","3  id27763  [how, lovely, is, spring, as, we, looked, from...      2\n","4  id12958  [finding, nothing, else, not, even, gold, the,...      1\n","5  id22965  [a, youth, passed, in, solitude, my, best, yea...      2\n","6  id09674  [the, astronomer, perhaps, at, this, point, to...      0\n","7  id13515  [the, surcingle, hung, in, ribands, from, my, ...      0\n","8  id19322  [i, knew, that, you, could, not, say, to, your...      0\n","9  id00912  [i, confess, that, neither, the, structure, of...      2\n","19579\n"]}]},{"cell_type":"code","metadata":{"id":"NTDiU36-zFFK","executionInfo":{"status":"ok","timestamp":1638632699971,"user_tz":300,"elapsed":13,"user":{"displayName":"Andrés Langoyo Martín","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12914381003507187562"}}},"source":["DOWNLOAD = True\n","# Use fastext or word2vec\n","FASTTEXT = False\n","WINDOW_SIZE = 7\n","\n","EMBEDDING_DIM = 300\n","HIDDEN_DIM = 512\n","NUM_LAYERS = 2\n","BIDIRECTIONAL = True\n"],"id":"NTDiU36-zFFK","execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kaqaR8CNzFFK","executionInfo":{"status":"ok","timestamp":1638633669589,"user_tz":300,"elapsed":969627,"user":{"displayName":"Andrés Langoyo Martín","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12914381003507187562"}},"outputId":"91ca407c-19de-490c-af98-2a83eaea2aab"},"source":["# Downloading or generating word2vec embeddings\n","\n","if DOWNLOAD:\n","    model = download_embeddings(FASTTEXT)\n","else:\n","    if FASTTEXT:\n","        model = gensim.models.FastText(sentences=train_df['text'], size=EMBEDDING_DIM, window=WINDOW_SIZE)\n","    else:\n","        model = gensim.models.Word2Vec(sentences=train_df['text'], size=EMBEDDING_DIM, window=WINDOW_SIZE)\n","                        "],"id":"kaqaR8CNzFFK","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[==================================================] 100.0% 1662.8/1662.8MB downloaded\n","\n","Loading complete!\n","Vocabulary size: 3000000\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fVz5UQwTzFFL","executionInfo":{"status":"ok","timestamp":1638633669590,"user_tz":300,"elapsed":11,"user":{"displayName":"Andrés Langoyo Martín","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12914381003507187562"}},"outputId":"e0d89fc4-9ca1-45de-ede6-2c6a60f30db5"},"source":["from src.dataset import HeadlineDataset\n","from torch.utils.data import RandomSampler\n","\n","train_dataset = HeadlineDataset(train_vocab, train_df,model.wv, FASTTEXT)\n","val_dataset = HeadlineDataset(train_vocab, val_df,model.wv, FASTTEXT)\n","test_dataset = HeadlineDataset(train_vocab, test_df,model.wv, FASTTEXT)\n","\n","# Now that we're wrapping our dataframes in PyTorch datsets, we can make use of PyTorch Random Samplers.\n","train_sampler = RandomSampler(train_dataset)\n","val_sampler = RandomSampler(val_dataset)\n","test_sampler = RandomSampler(test_dataset)"],"id":"fVz5UQwTzFFL","execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  \"\"\"\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  \n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gnfaq2kpzFFM","executionInfo":{"status":"ok","timestamp":1638633669590,"user_tz":300,"elapsed":7,"user":{"displayName":"Andrés Langoyo Martín","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12914381003507187562"}},"outputId":"09925320-2e18-4636-d8a0-94cd45d2c69b"},"source":["from torch.utils.data import DataLoader\n","from src.dataset import collate_fn\n","BATCH_SIZE = 16\n","train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, collate_fn=collate_fn)\n","val_iterator = DataLoader(val_dataset, batch_size=BATCH_SIZE, sampler=val_sampler, collate_fn=collate_fn)\n","test_iterator = DataLoader(test_dataset, batch_size=BATCH_SIZE, sampler=test_sampler, collate_fn=collate_fn)\n","\n","for x, y in test_iterator:\n","    print(x,y)\n","    break"],"id":"gnfaq2kpzFFM","execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/content/src/dataset.py:161: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  tokenized_word_tensor = torch.Tensor(tmp)\n"]},{"output_type":"stream","name":"stdout","text":["tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.1797, -0.0913, -0.1553,  ..., -0.1143, -0.0378, -0.1514],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         ...,\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n","\n","        [[-0.2256, -0.0195,  0.0908,  ...,  0.0282, -0.1777, -0.0060],\n","         [ 0.0771, -0.1396,  0.1445,  ..., -0.0845,  0.2002, -0.3145],\n","         [-0.0332, -0.0327, -0.0598,  ..., -0.0058,  0.1299, -0.0209],\n","         ...,\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n","\n","        [[ 0.0884, -0.0317, -0.1226,  ...,  0.0234,  0.2480, -0.1177],\n","         [-0.0581,  0.0581,  0.0133,  ..., -0.1748, -0.0231, -0.0435],\n","         [ 0.0850, -0.0952,  0.1191,  ..., -0.1089,  0.0488, -0.1309],\n","         ...,\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n","\n","        ...,\n","\n","        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0510, -0.0008,  0.1826,  ..., -0.1680, -0.2266,  0.0160],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         ...,\n","         [ 0.0698, -0.0378, -0.0400,  ...,  0.0041,  0.0009, -0.1196],\n","         [-0.0679,  0.0952,  0.0356,  ...,  0.1270, -0.1035,  0.0476],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n","\n","        [[ 0.0825, -0.1514,  0.0659,  ..., -0.1016, -0.1084, -0.2051],\n","         [ 0.0304, -0.1582,  0.0012,  ...,  0.0371, -0.2041, -0.0898],\n","         [ 0.0260, -0.0019,  0.1855,  ..., -0.1216,  0.2217, -0.0220],\n","         ...,\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n","\n","        [[-0.0078, -0.0280,  0.0405,  ...,  0.0396, -0.0605,  0.0081],\n","         [ 0.0947, -0.1187,  0.1182,  ...,  0.0972, -0.0996, -0.0090],\n","         [ 0.2129,  0.0737,  0.0537,  ..., -0.1602, -0.0581, -0.0154],\n","         ...,\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]) tensor([0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 2, 2, 2, 2, 0, 1])\n"]}]},{"cell_type":"markdown","metadata":{"id":"FvFz28NgzFFM"},"source":["### Modeling"],"id":"FvFz28NgzFFM"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E54k4vH-zFFO","executionInfo":{"status":"ok","timestamp":1638633679917,"user_tz":300,"elapsed":10332,"user":{"displayName":"Andrés Langoyo Martín","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12914381003507187562"}},"outputId":"c3befe76-9146-434f-a553-5a71e405e3bf"},"source":["from src.models import ClassificationModel\n","\n","model = ClassificationModel(len(train_vocab),embedding_dim=EMBEDDING_DIM,hidden_dim = HIDDEN_DIM,num_layers = NUM_LAYERS,bidirectional = BIDIRECTIONAL)\n","\n","model.to(device)"],"id":"E54k4vH-zFFO","execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ClassificationModel(\n","  (LSTM): LSTM(300, 512, num_layers=2, batch_first=True, bidirectional=True)\n","  (linear): Linear(in_features=1024, out_features=3, bias=True)\n","  (softmax): Softmax(dim=1)\n",")"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"PeoanbgVzFFO"},"source":["In the following cell, **instantiate the model with some hyperparameters, and select an appropriate loss function and optimizer.** \n","\n","Hint: we already use sigmoid in our model. What loss functions are availible for binary classification? Feel free to look at PyTorch docs for help!"],"id":"PeoanbgVzFFO"},{"cell_type":"code","metadata":{"id":"4rcqsWzHzFFP","executionInfo":{"status":"ok","timestamp":1638633679918,"user_tz":300,"elapsed":40,"user":{"displayName":"Andrés Langoyo Martín","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12914381003507187562"}}},"source":["from torch.optim import AdamW\n","\n","criterion, optimizer = torch.nn.CrossEntropyLoss(), torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)"],"id":"4rcqsWzHzFFP","execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kNFrnFAVzFFP"},"source":["### Part 3: Training and Evaluation [10 Points]\n","The final part of this HW involves training the model, and evaluating it at each epoch. **Fill out the train and test loops below.**"],"id":"kNFrnFAVzFFP"},{"cell_type":"code","metadata":{"id":"4WOY7B-azFFP","executionInfo":{"status":"ok","timestamp":1638633679919,"user_tz":300,"elapsed":37,"user":{"displayName":"Andrés Langoyo Martín","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12914381003507187562"}}},"source":["# returns the total loss calculated from criterion\n","def train_loop(model, criterion, iterator):\n","    model.train()\n","    total_loss = 0\n","    \n","    for x, y in tqdm(iterator):\n","        x = x.to(device)\n","        y = y.to(device)\n","        optimizer.zero_grad()\n","\n","        prediction = model(x)\n","        prediction = torch.squeeze(prediction)\n","        # y = y.round()\n","        # y = y.long()\n","        \n","\n"," \n","        loss = criterion(prediction,y)\n","        total_loss += loss.item()\n","        loss.backward()\n","        optimizer.step()\n","\n","    return total_loss\n","\n","# returns:\n","# - true: a Python boolean array of all the ground truth values \n","#         taken from the dataset iterator\n","# - pred: a Python boolean array of all model predictions. \n","def val_loop(model, criterion, iterator):\n","    true, pred = [], []\n","    for x, y in tqdm(iterator):\n","        x = x.to(device)\n","        y = y.to(device)\n","    \n","        preds = model(x)\n","        preds.to(device)\n","        preds = torch.squeeze(preds)\n","        for i_batch in range(len(y)):\n","            true.append(y[i_batch])\n","            pred.append(torch.argmax(preds[i_batch]))\n","            \n","    return true, pred\n"],"id":"4WOY7B-azFFP","execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RwyLMPAwzFFQ","executionInfo":{"status":"ok","timestamp":1638633685799,"user_tz":300,"elapsed":5915,"user":{"displayName":"Andrés Langoyo Martín","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12914381003507187562"}},"outputId":"1bf0b97d-2ded-4fb7-c4ec-c7ce1c2040a8"},"source":["# To test your eval implementation, let's see how well the untrained model does on our dev dataset.\n","# It should do pretty poorly.\n","from src.eval_utils import binary_macro_f1, accuracy\n","true, pred = val_loop(model, criterion, val_iterator)\n","# print(binary_macro_f1(true, pred))\n","# print(accuracy(true, pred))\n"],"id":"RwyLMPAwzFFQ","execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 123/123 [00:05<00:00, 24.06it/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"klS-hqCezFFQ"},"source":["### Actually training the model"],"id":"klS-hqCezFFQ"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PS8EQy8SzFFQ","executionInfo":{"status":"ok","timestamp":1638636697758,"user_tz":300,"elapsed":3011986,"user":{"displayName":"Andrés Langoyo Martín","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12914381003507187562"}},"outputId":"108f0941-f7a6-48dd-c8c0-caa3342edd37"},"source":["TOTAL_EPOCHS = 20\n","for epoch in range(TOTAL_EPOCHS):\n","    train_loss = train_loop(model, criterion, train_iterator)\n","    true, pred = val_loop(model, criterion, val_iterator)\n","    print(f\"EPOCH: {epoch}\")\n","    print(f\"TRAIN LOSS: {train_loss}\")\n","    print(f\"VAL F-1: {binary_macro_f1(true, pred)}\")\n","    print(f\"VAL ACC: {accuracy(true, pred)}\")\n"],"id":"PS8EQy8SzFFQ","execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 979/979 [02:32<00:00,  6.44it/s]\n","100%|██████████| 123/123 [00:04<00:00, 24.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["EPOCH: 0\n","TRAIN LOSS: 1000.0313270688057\n","VAL F-1: 0.5770874829168147\n","VAL ACC: 0.5769034236075626\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 979/979 [02:31<00:00,  6.48it/s]\n","100%|██████████| 123/123 [00:04<00:00, 25.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["EPOCH: 1\n","TRAIN LOSS: 942.1972339749336\n","VAL F-1: 0.5936830166164149\n","VAL ACC: 0.6050076647930506\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 979/979 [02:29<00:00,  6.53it/s]\n","100%|██████████| 123/123 [00:04<00:00, 24.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["EPOCH: 2\n","TRAIN LOSS: 800.6480236947536\n","VAL F-1: 0.6722938120897061\n","VAL ACC: 0.6729688298415942\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 979/979 [02:31<00:00,  6.48it/s]\n","100%|██████████| 123/123 [00:04<00:00, 25.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["EPOCH: 3\n","TRAIN LOSS: 716.2159390002489\n","VAL F-1: 0.6607763272435196\n","VAL ACC: 0.6642820643842616\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 979/979 [02:25<00:00,  6.71it/s]\n","100%|██████████| 123/123 [00:04<00:00, 26.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["EPOCH: 4\n","TRAIN LOSS: 662.8433213979006\n","VAL F-1: 0.720984600801737\n","VAL ACC: 0.7199795605518651\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 979/979 [02:23<00:00,  6.84it/s]\n","100%|██████████| 123/123 [00:04<00:00, 26.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["EPOCH: 5\n","TRAIN LOSS: 608.9507778435946\n","VAL F-1: 0.7146105859991924\n","VAL ACC: 0.7199795605518651\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 979/979 [02:24<00:00,  6.76it/s]\n","100%|██████████| 123/123 [00:04<00:00, 26.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["EPOCH: 6\n","TRAIN LOSS: 564.5167116299272\n","VAL F-1: 0.7204696578638852\n","VAL ACC: 0.7210015329586101\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 979/979 [02:23<00:00,  6.83it/s]\n","100%|██████████| 123/123 [00:04<00:00, 26.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["EPOCH: 7\n","TRAIN LOSS: 522.6278914809227\n","VAL F-1: 0.7400267545922364\n","VAL ACC: 0.740929994890138\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 979/979 [02:22<00:00,  6.87it/s]\n","100%|██████████| 123/123 [00:04<00:00, 26.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["EPOCH: 8\n","TRAIN LOSS: 497.16423062235117\n","VAL F-1: 0.7414763474366738\n","VAL ACC: 0.740929994890138\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 979/979 [02:22<00:00,  6.87it/s]\n","100%|██████████| 123/123 [00:04<00:00, 26.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["EPOCH: 9\n","TRAIN LOSS: 456.0402592010796\n","VAL F-1: 0.7321923313649958\n","VAL ACC: 0.7342871742462953\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 979/979 [02:22<00:00,  6.85it/s]\n","100%|██████████| 123/123 [00:04<00:00, 25.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["EPOCH: 10\n","TRAIN LOSS: 425.5233007967472\n","VAL F-1: 0.7256376154888545\n","VAL ACC: 0.7250894225855902\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 979/979 [02:19<00:00,  7.01it/s]\n","100%|██████████| 123/123 [00:04<00:00, 26.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["EPOCH: 11\n","TRAIN LOSS: 381.4862082824111\n","VAL F-1: 0.7327042146224879\n","VAL ACC: 0.7317322432294328\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 979/979 [02:20<00:00,  6.97it/s]\n","100%|██████████| 123/123 [00:04<00:00, 25.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["EPOCH: 12\n","TRAIN LOSS: 344.6356770209968\n","VAL F-1: 0.7183600285381923\n","VAL ACC: 0.7215125191619827\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 979/979 [02:20<00:00,  6.95it/s]\n","100%|██████████| 123/123 [00:04<00:00, 27.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["EPOCH: 13\n","TRAIN LOSS: 305.57615879084915\n","VAL F-1: 0.72762929513329\n","VAL ACC: 0.7271333673990802\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 979/979 [02:20<00:00,  6.97it/s]\n","100%|██████████| 123/123 [00:04<00:00, 25.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["EPOCH: 14\n","TRAIN LOSS: 279.14132490567863\n","VAL F-1: 0.7362752574501735\n","VAL ACC: 0.7363311190597854\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 979/979 [02:22<00:00,  6.87it/s]\n","100%|██████████| 123/123 [00:04<00:00, 25.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["EPOCH: 15\n","TRAIN LOSS: 234.77847710438073\n","VAL F-1: 0.7405425515214948\n","VAL ACC: 0.740929994890138\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 979/979 [02:23<00:00,  6.82it/s]\n","100%|██████████| 123/123 [00:04<00:00, 26.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["EPOCH: 16\n","TRAIN LOSS: 195.717875294853\n","VAL F-1: 0.733681870773233\n","VAL ACC: 0.7337761880429229\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 979/979 [02:28<00:00,  6.58it/s]\n","100%|██████████| 123/123 [00:04<00:00, 25.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["EPOCH: 17\n","TRAIN LOSS: 175.09464340494014\n","VAL F-1: 0.7343720155354642\n","VAL ACC: 0.7363311190597854\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 979/979 [02:26<00:00,  6.69it/s]\n","100%|██████████| 123/123 [00:04<00:00, 25.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["EPOCH: 18\n","TRAIN LOSS: 145.63777079596184\n","VAL F-1: 0.7105345217775607\n","VAL ACC: 0.711803781297905\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 979/979 [02:26<00:00,  6.68it/s]\n","100%|██████████| 123/123 [00:04<00:00, 25.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["EPOCH: 19\n","TRAIN LOSS: 134.48625293577788\n","VAL F-1: 0.7373006118930997\n","VAL ACC: 0.7383750638732755\n"]}]},{"cell_type":"markdown","metadata":{"id":"ECkuloBSzFFR"},"source":["We can also look at the models performance on the held-out test set, using the same val_loop we wrote earlier."],"id":"ECkuloBSzFFR"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E9S33DF4zFFR","executionInfo":{"status":"ok","timestamp":1638636704240,"user_tz":300,"elapsed":6491,"user":{"displayName":"Andrés Langoyo Martín","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12914381003507187562"}},"outputId":"5d3afe4c-d9db-4935-92a8-029dc6c95a31"},"source":["true, pred = val_loop(model, criterion, test_iterator)\n","print(f\"TEST F-1: {binary_macro_f1(true, pred)}\")\n","print(f\"TEST ACC: {accuracy(true, pred)}\")"],"id":"E9S33DF4zFFR","execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 123/123 [00:05<00:00, 24.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TEST F-1: 0.7150672020517449\n","TEST ACC: 0.717935615738375\n"]}]}]}