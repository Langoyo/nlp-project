{"nbformat":4,"nbformat_minor":5,"metadata":{"accelerator":"GPU","colab":{"name":"fasttext.ipynb","provenance":[],"collapsed_sections":[]},"interpreter":{"hash":"8abf625e542ff33194dd4502f291ce11b7bf8daed732e6d5f31b5a030b27ce17"},"kernelspec":{"display_name":"Python 3.9.5 64-bit ('base': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"}},"cells":[{"cell_type":"code","metadata":{"id":"1yv5wo80zFFD","executionInfo":{"status":"ok","timestamp":1638630941744,"user_tz":300,"elapsed":526,"user":{"displayName":"Andrés Langoyo Martín","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12914381003507187562"}}},"source":["import torch\n","import random\n","import numpy as np\n","import regex\n","\n","RANDOM_SEED = 42\n","torch.manual_seed(RANDOM_SEED)\n","random.seed(RANDOM_SEED)\n","np.random.seed(RANDOM_SEED)\n","\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"id":"1yv5wo80zFFD","execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"_4lpUGTQzFFI","executionInfo":{"status":"ok","timestamp":1638630941991,"user_tz":300,"elapsed":17,"user":{"displayName":"Andrés Langoyo Martín","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12914381003507187562"}}},"source":["def split_train_val_test(df, props=[.8, .1, .1]):\n","    assert round(sum(props), 2) == 1 and len(props) >= 2\n","    train_df, test_df, val_df = None, None, None\n","\n","    train_size = int(props[0] * len(df))\n","    val_size =  train_size + int(props[1] * len(df))\n","    test_size =val_size + int(props[2] * len(df)) \n","    train_df = df.iloc[0:train_size]\n","    val_df = df.iloc[train_size:val_size]\n","    test_df = df.iloc[val_size:test_size]\n","    \n","    return train_df, val_df, test_df"],"id":"_4lpUGTQzFFI","execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"u04VW4ugzFFI","executionInfo":{"status":"ok","timestamp":1638630941992,"user_tz":300,"elapsed":16,"user":{"displayName":"Andrés Langoyo Martín","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12914381003507187562"}}},"source":["import gensim.downloader as api\n","\n","def download_embeddings(fasttetxt):\n","    # https://fasttext.cc/docs/en/english-vectors.html\n","    if fasttetxt:\n","      wv = api.load(\"fasttext-wiki-news-subwords-300\")\n","    else:\n","      \n","      wv = api.load(\"word2vec-google-news-300\")\n","      print(\"\\nLoading complete!\\n\" +\n","            \"Vocabulary size: {}\".format(len(wv.vocab)))\n","    return wv\n"],"id":"u04VW4ugzFFI","execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"23WpDX0rzFFJ","executionInfo":{"status":"ok","timestamp":1638630954523,"user_tz":300,"elapsed":12545,"user":{"displayName":"Andrés Langoyo Martín","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12914381003507187562"}},"outputId":"c58730da-6a62-4ffe-ea99-bb7583819aa5"},"source":["# Opening and preprocessing input file\n","import gensim.models\n","import pandas as pd\n","import nltk\n","nltk.download('punkt')\n","from tqdm import tqdm\n","from src.preprocess import clean_text\n","\n","data = pd.read_csv('train.csv', quotechar='\"')\n","data.sample(frac=1)\n","\n","\n","# to convert authors into numbers\n","author_to_number = {\n","    'EAP': 0,\n","    'HPL': 1,\n","    'MWS': 2\n","    \n","}\n","\n","# lowercase, removing punctuation and tookenize sentences. Converting labels to int\n","training_text = \"\"\n","for i in range(len(data)):\n","\n","    data['text'][i] = nltk.word_tokenize(regex.sub(r'[^\\w\\s]', '',data['text'][i].lower()))\n","    data['author'][i] = author_to_number[data['author'][i]]\n","\n","print(data[0:10])\n","print(len(data))\n","\n","from src.dataset import *\n","\n","# Splitting dataset and generating vocab\n","train_df, val_df, test_df = split_train_val_test(data)\n","train_vocab, reversed_vocab = generate_vocab_map(train_df)\n","\n"],"id":"23WpDX0rzFFJ","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","        id                                               text author\n","0  id26305  [this, process, however, afforded, me, no, mea...      0\n","1  id17569  [it, never, once, occurred, to, me, that, the,...      1\n","2  id11008  [in, his, left, hand, was, a, gold, snuff, box...      0\n","3  id27763  [how, lovely, is, spring, as, we, looked, from...      2\n","4  id12958  [finding, nothing, else, not, even, gold, the,...      1\n","5  id22965  [a, youth, passed, in, solitude, my, best, yea...      2\n","6  id09674  [the, astronomer, perhaps, at, this, point, to...      0\n","7  id13515  [the, surcingle, hung, in, ribands, from, my, ...      0\n","8  id19322  [i, knew, that, you, could, not, say, to, your...      0\n","9  id00912  [i, confess, that, neither, the, structure, of...      2\n","19579\n"]}]},{"cell_type":"code","metadata":{"id":"NTDiU36-zFFK","executionInfo":{"status":"ok","timestamp":1638630954525,"user_tz":300,"elapsed":17,"user":{"displayName":"Andrés Langoyo Martín","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12914381003507187562"}}},"source":["DOWNLOAD = False\n","# Use fastext or word2vec\n","FASTTEXT = True\n","WINDOW_SIZE = 7\n","\n","EMBEDDING_DIM = 300\n","HIDDEN_DIM = 512\n","NUM_LAYERS = 2\n","BIDIRECTIONAL = True\n"],"id":"NTDiU36-zFFK","execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"kaqaR8CNzFFK","executionInfo":{"status":"ok","timestamp":1638630980612,"user_tz":300,"elapsed":26099,"user":{"displayName":"Andrés Langoyo Martín","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12914381003507187562"}}},"source":["# Downloading or generating word2vec embeddings\n","\n","if DOWNLOAD:\n","    model = download_embeddings(FASTTEXT)\n","else:\n","    if FASTTEXT:\n","        model = gensim.models.FastText(sentences=train_df['text'], size=EMBEDDING_DIM, window=WINDOW_SIZE)\n","    else:\n","        model = gensim.models.Word2Vec(sentences=train_df['text'], size=EMBEDDING_DIM, window=WINDOW_SIZE)\n","                        "],"id":"kaqaR8CNzFFK","execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"fVz5UQwTzFFL","executionInfo":{"status":"ok","timestamp":1638630980613,"user_tz":300,"elapsed":38,"user":{"displayName":"Andrés Langoyo Martín","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12914381003507187562"}}},"source":["from src.dataset import HeadlineDataset\n","from torch.utils.data import RandomSampler\n","\n","train_dataset = HeadlineDataset(train_vocab, train_df,model.wv, FASTTEXT)\n","val_dataset = HeadlineDataset(train_vocab, val_df,model.wv, FASTTEXT)\n","test_dataset = HeadlineDataset(train_vocab, test_df,model.wv, FASTTEXT)\n","\n","# Now that we're wrapping our dataframes in PyTorch datsets, we can make use of PyTorch Random Samplers.\n","train_sampler = RandomSampler(train_dataset)\n","val_sampler = RandomSampler(val_dataset)\n","test_sampler = RandomSampler(test_dataset)"],"id":"fVz5UQwTzFFL","execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gnfaq2kpzFFM","executionInfo":{"status":"ok","timestamp":1638630981061,"user_tz":300,"elapsed":454,"user":{"displayName":"Andrés Langoyo Martín","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12914381003507187562"}},"outputId":"4f594211-1257-494a-9155-a718514e6aae"},"source":["from torch.utils.data import DataLoader\n","from src.dataset import collate_fn\n","BATCH_SIZE = 16\n","train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, collate_fn=collate_fn)\n","val_iterator = DataLoader(val_dataset, batch_size=BATCH_SIZE, sampler=val_sampler, collate_fn=collate_fn)\n","test_iterator = DataLoader(test_dataset, batch_size=BATCH_SIZE, sampler=test_sampler, collate_fn=collate_fn)\n","\n","for x, y in test_iterator:\n","    print(x,y)\n","    break"],"id":"gnfaq2kpzFFM","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[ 4.4139e-01, -2.7224e-01,  5.2760e-01,  ...,  6.7636e-02,\n","           3.6349e-01,  1.9107e-01],\n","         [-7.0321e-03,  9.5343e-02,  9.3443e-02,  ...,  2.4066e-02,\n","           1.1802e-01, -4.5151e-02],\n","         [ 4.0009e-01,  3.1827e-02,  4.8509e-01,  ...,  1.5147e-02,\n","          -3.1777e-01,  1.2548e-01],\n","         ...,\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00]],\n","\n","        [[-1.8270e-01,  9.4614e-01,  2.2865e-01,  ...,  2.2509e-01,\n","           3.8513e-01, -6.8979e-01],\n","         [-6.4942e-02,  1.4821e-01,  1.0785e-01,  ...,  3.7031e-02,\n","           2.3024e-01, -8.1881e-02],\n","         [-1.5959e-01,  4.8510e-02, -2.3154e-02,  ..., -2.7851e-02,\n","           2.7244e-01,  5.4769e-02],\n","         ...,\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00]],\n","\n","        [[-5.9893e-01, -3.3901e-01, -1.5730e-01,  ...,  5.3361e-02,\n","           3.1395e-01,  4.5564e-02],\n","         [-6.1511e-01, -7.1320e-02, -4.4826e-01,  ..., -7.6376e-03,\n","           9.3362e-02,  3.9044e-01],\n","         [ 6.5793e-02,  7.9623e-01,  2.4354e-01,  ...,  1.9046e-01,\n","           3.9073e-01, -4.1636e-01],\n","         ...,\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00]],\n","\n","        ...,\n","\n","        [[ 4.4139e-01, -2.7224e-01,  5.2760e-01,  ...,  6.7636e-02,\n","           3.6349e-01,  1.9107e-01],\n","         [-4.0221e-03,  6.8049e-02,  9.1386e-02,  ..., -7.1155e-04,\n","           1.2800e-01, -1.7259e-02],\n","         [ 4.0009e-01,  3.1827e-02,  4.8509e-01,  ...,  1.5147e-02,\n","          -3.1777e-01,  1.2548e-01],\n","         ...,\n","         [-1.6730e-01,  8.7602e-02, -1.3359e-02,  ...,  6.9359e-02,\n","           2.2104e-01, -5.6468e-02],\n","         [-2.4436e-02,  1.7898e-01,  1.2409e-01,  ...,  4.7836e-02,\n","           1.1283e-01, -1.4697e-01],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00]],\n","\n","        [[ 1.9194e-01,  5.3636e-01,  1.3579e-01,  ...,  1.9752e-01,\n","           3.1060e-01, -8.5391e-02],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00],\n","         [-1.0312e-01,  1.7011e-01, -2.2958e-01,  ..., -8.2452e-02,\n","           1.1698e-01,  1.3885e-01],\n","         ...,\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00]],\n","\n","        [[ 1.2797e-01,  3.2689e-01,  2.3726e-01,  ..., -6.2591e-02,\n","           3.5835e-01, -1.9010e-01],\n","         [-1.4064e-02,  2.1937e-02,  1.2940e-01,  ..., -1.8182e-02,\n","           1.8913e-01,  4.4746e-02],\n","         [-3.2618e-01, -9.4624e-02, -8.9202e-02,  ...,  3.1364e-02,\n","           4.1611e-01, -4.1772e-02],\n","         ...,\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00]]]) tensor([0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 2, 2, 2, 2, 0, 1])\n"]},{"output_type":"stream","name":"stderr","text":["/content/src/dataset.py:161: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  tokenized_word_tensor = torch.Tensor(tmp)\n"]}]},{"cell_type":"markdown","metadata":{"id":"FvFz28NgzFFM"},"source":["### Modeling"],"id":"FvFz28NgzFFM"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E54k4vH-zFFO","executionInfo":{"status":"ok","timestamp":1638630988920,"user_tz":300,"elapsed":7862,"user":{"displayName":"Andrés Langoyo Martín","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12914381003507187562"}},"outputId":"5b4368cf-d023-4c7f-bbad-99f9b2cad909"},"source":["from src.models import ClassificationModel\n","\n","model = ClassificationModel(len(train_vocab),embedding_dim=EMBEDDING_DIM,hidden_dim = HIDDEN_DIM,num_layers = NUM_LAYERS,bidirectional = BIDIRECTIONAL)\n","\n","model.to(device)"],"id":"E54k4vH-zFFO","execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ClassificationModel(\n","  (LSTM): LSTM(300, 512, num_layers=2, batch_first=True, bidirectional=True)\n","  (linear): Linear(in_features=1024, out_features=3, bias=True)\n","  (softmax): Softmax(dim=1)\n",")"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"PeoanbgVzFFO"},"source":["In the following cell, **instantiate the model with some hyperparameters, and select an appropriate loss function and optimizer.** \n","\n","Hint: we already use sigmoid in our model. What loss functions are availible for binary classification? Feel free to look at PyTorch docs for help!"],"id":"PeoanbgVzFFO"},{"cell_type":"code","metadata":{"id":"4rcqsWzHzFFP","executionInfo":{"status":"ok","timestamp":1638630988920,"user_tz":300,"elapsed":7,"user":{"displayName":"Andrés Langoyo Martín","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12914381003507187562"}}},"source":["from torch.optim import AdamW\n","\n","criterion, optimizer = torch.nn.CrossEntropyLoss(), torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)"],"id":"4rcqsWzHzFFP","execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kNFrnFAVzFFP"},"source":["### Part 3: Training and Evaluation [10 Points]\n","The final part of this HW involves training the model, and evaluating it at each epoch. **Fill out the train and test loops below.**"],"id":"kNFrnFAVzFFP"},{"cell_type":"code","metadata":{"id":"4WOY7B-azFFP","executionInfo":{"status":"ok","timestamp":1638630988921,"user_tz":300,"elapsed":7,"user":{"displayName":"Andrés Langoyo Martín","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12914381003507187562"}}},"source":["# returns the total loss calculated from criterion\n","def train_loop(model, criterion, iterator):\n","    model.train()\n","    total_loss = 0\n","    \n","    for x, y in tqdm(iterator):\n","        x = x.to(device)\n","        y = y.to(device)\n","        optimizer.zero_grad()\n","\n","        prediction = model(x)\n","        prediction = torch.squeeze(prediction)\n","        # y = y.round()\n","        # y = y.long()\n","        \n","\n"," \n","        loss = criterion(prediction,y)\n","        total_loss += loss.item()\n","        loss.backward()\n","        optimizer.step()\n","\n","    return total_loss\n","\n","# returns:\n","# - true: a Python boolean array of all the ground truth values \n","#         taken from the dataset iterator\n","# - pred: a Python boolean array of all model predictions. \n","def val_loop(model, criterion, iterator):\n","    true, pred = [], []\n","    for x, y in tqdm(iterator):\n","        x = x.to(device)\n","        y = y.to(device)\n","    \n","        preds = model(x)\n","        preds.to(device)\n","        preds = torch.squeeze(preds)\n","        for i_batch in range(len(y)):\n","            true.append(y[i_batch])\n","            pred.append(torch.argmax(preds[i_batch]))\n","            \n","    return true, pred\n"],"id":"4WOY7B-azFFP","execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RwyLMPAwzFFQ","executionInfo":{"status":"ok","timestamp":1638630994194,"user_tz":300,"elapsed":5280,"user":{"displayName":"Andrés Langoyo Martín","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12914381003507187562"}},"outputId":"cbca1c89-55ab-41ea-911d-26f64105b9da"},"source":["# To test your eval implementation, let's see how well the untrained model does on our dev dataset.\n","# It should do pretty poorly.\n","from src.eval_utils import binary_macro_f1, accuracy\n","true, pred = val_loop(model, criterion, val_iterator)\n","# print(binary_macro_f1(true, pred))\n","# print(accuracy(true, pred))\n"],"id":"RwyLMPAwzFFQ","execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 123/123 [00:05<00:00, 24.21it/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"klS-hqCezFFQ"},"source":["### Actually training the model"],"id":"klS-hqCezFFQ"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PS8EQy8SzFFQ","executionInfo":{"status":"ok","timestamp":1638632098170,"user_tz":300,"elapsed":1103995,"user":{"displayName":"Andrés Langoyo Martín","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12914381003507187562"}},"outputId":"24e0d1b2-87d3-4c8b-9c7b-186011e30648"},"source":["TOTAL_EPOCHS = 7\n","for epoch in range(TOTAL_EPOCHS):\n","    train_loss = train_loop(model, criterion, train_iterator)\n","    true, pred = val_loop(model, criterion, val_iterator)\n","    print(f\"EPOCH: {epoch}\")\n","    print(f\"TRAIN LOSS: {train_loss}\")\n","    print(f\"VAL F-1: {binary_macro_f1(true, pred)}\")\n","    print(f\"VAL ACC: {accuracy(true, pred)}\")\n"],"id":"PS8EQy8SzFFQ","execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 979/979 [02:33<00:00,  6.38it/s]\n","100%|██████████| 123/123 [00:05<00:00, 24.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["EPOCH: 0\n","TRAIN LOSS: 1045.5065363049507\n","VAL F-1: 0.46572718800172846\n","VAL ACC: 0.513030148185999\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 979/979 [02:31<00:00,  6.47it/s]\n","100%|██████████| 123/123 [00:04<00:00, 25.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["EPOCH: 1\n","TRAIN LOSS: 973.986906170845\n","VAL F-1: 0.5075201107035069\n","VAL ACC: 0.5227388860500767\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 979/979 [02:30<00:00,  6.49it/s]\n","100%|██████████| 123/123 [00:04<00:00, 25.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["EPOCH: 2\n","TRAIN LOSS: 948.9056264162064\n","VAL F-1: 0.5251245243631559\n","VAL ACC: 0.5498211548288197\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 979/979 [02:32<00:00,  6.43it/s]\n","100%|██████████| 123/123 [00:04<00:00, 25.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["EPOCH: 3\n","TRAIN LOSS: 934.6561287045479\n","VAL F-1: 0.5251526699600094\n","VAL ACC: 0.541134389371487\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 979/979 [02:31<00:00,  6.44it/s]\n","100%|██████████| 123/123 [00:04<00:00, 25.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["EPOCH: 4\n","TRAIN LOSS: 916.4464963674545\n","VAL F-1: 0.5564292488458155\n","VAL ACC: 0.5625958099131323\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 979/979 [02:31<00:00,  6.45it/s]\n","100%|██████████| 123/123 [00:04<00:00, 24.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["EPOCH: 5\n","TRAIN LOSS: 901.6297101974487\n","VAL F-1: 0.549138283552097\n","VAL ACC: 0.5687276443536025\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 979/979 [02:31<00:00,  6.45it/s]\n","100%|██████████| 123/123 [00:04<00:00, 25.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["EPOCH: 6\n","TRAIN LOSS: 886.2818676233292\n","VAL F-1: 0.579039976988319\n","VAL ACC: 0.5779253960143076\n"]}]},{"cell_type":"markdown","metadata":{"id":"ECkuloBSzFFR"},"source":["We can also look at the models performance on the held-out test set, using the same val_loop we wrote earlier."],"id":"ECkuloBSzFFR"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E9S33DF4zFFR","executionInfo":{"status":"ok","timestamp":1638632104201,"user_tz":300,"elapsed":6056,"user":{"displayName":"Andrés Langoyo Martín","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12914381003507187562"}},"outputId":"7058a847-3876-4a16-d076-e37648f96fda"},"source":["true, pred = val_loop(model, criterion, test_iterator)\n","print(f\"TEST F-1: {binary_macro_f1(true, pred)}\")\n","print(f\"TEST ACC: {accuracy(true, pred)}\")"],"id":"E9S33DF4zFFR","execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 123/123 [00:05<00:00, 24.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TEST F-1: 0.5703646264844852\n","TEST ACC: 0.5707715891670925\n"]}]}]}